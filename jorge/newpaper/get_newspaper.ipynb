{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import feedparser as fp\n",
    "import json\n",
    "import newspaper\n",
    "from newspaper import Article\n",
    "from time import mktime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['newspapers'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'newspapers': {}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newspapers.json') as data_file:\n",
    "    companies = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='newspapers.json' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading articles from  newyorktimes_business\n",
      "10 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/20/health/coronavirus-vaccines.html\n",
      "20 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/19/style/soulcycle-peloton-home-exercise-bikes-coronavirus.html\n",
      "30 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/19/business/economy/china-taiwan-huawei-tsmc.html\n",
      "40 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/18/business/media/tiktok-ceo-kevin-mayer.html\n",
      "50 articles downloaded from newyorktimes_business , url:  https://www.nytimes.com/2020/05/18/business/minority-businesses-coronavirus-loans.html\n",
      "Downloading articles from  newyorktimes_science\n",
      "10 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/20/world/asia/cyclone-amphan-india-bangladesh.html\n",
      "20 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/19/health/pandemic-coronavirus-suicide-health.html\n",
      "30 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/18/health/coronavirus-vaccine-moderna.html\n",
      "40 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/16/world/coronavirus-live.html\n",
      "50 articles downloaded from newyorktimes_science , url:  https://www.nytimes.com/2020/05/14/business/coronavirus-farmers-killing-pigs.html\n",
      "Downloading articles from  newyorktimes_technology\n",
      "10 articles downloaded from newyorktimes_technology , url:  https://www.nytimes.com/2020/05/19/technology/online-shopping-effects.html\n",
      "20 articles downloaded from newyorktimes_technology , url:  https://www.nytimes.com/2020/05/16/technology/zuckerberg-facebook-coronavirus.html\n",
      "Downloading articles from  cnnmoney\n",
      "Downloading articles from  marketwatch_newsletters\n",
      "Article `download()` failed with HTTPConnectionPool(host='feeds.marketwatch.com', port=80): Read timed out. (read timeout=7) on URL http://feeds.marketwatch.com/~r/marketwatch/newslettersAndresearch/~3/geDvYWw8ou8/story.asp\n",
      "continuing...\n",
      "Downloading articles from  marketwatch_stories\n",
      "10 articles downloaded from marketwatch_stories , url:  http://www.marketwatch.com/news/story.asp?guid=%7B92DD9EC0-99DC-11EA-AA68-70C601ED7B47%7D&siteid=rss&rss=1\n",
      "Downloading articles from  cnbc_top_news\n",
      "10 articles downloaded from cnbc_top_news , url:  https://www.cnbc.com/2020/05/20/moderna-would-never-release-coronavirus-vaccine-data-different-from-reality-chairman-says.html\n",
      "20 articles downloaded from cnbc_top_news , url:  https://www.cnbc.com/2020/05/20/pro-biden-super-pac-sees-fundraising-dip-during-coronavirus-lockdown.html\n",
      "30 articles downloaded from cnbc_top_news , url:  https://www.cnbc.com/2020/05/20/youtube-exec-covid-themed-ads-dont-work-but-scrappy-ads-do.html\n",
      "Downloading articles from  cnbc_investing\n",
      "10 articles downloaded from cnbc_investing , url:  https://www.cnbc.com/2020/05/13/bill-miller-doesnt-see-market-as-dramatically-overvalued-says-amazon-could-double-in-3-years.html\n",
      "20 articles downloaded from cnbc_investing , url:  https://www.cnbc.com/2020/05/09/bill-ackman-looks-to-find-another-winner-with-restaurant-brands.html\n",
      "30 articles downloaded from cnbc_investing , url:  https://www.cnbc.com/2020/05/06/jim-cramer-plant-based-meat-is-a-trend-investors-should-not-ignore.html\n",
      "Downloading articles from  marketwatch\n",
      "10 articles downloaded from marketwatch , url:  https://www.theguardian.com/uk-news/2020/may/21/face-mask-rules-more-political-than-scientific-says-expert\n",
      "20 articles downloaded from marketwatch , url:  https://www.theguardian.com/commentisfree/2020/may/20/british-schools-science-children-education-testing-tracing\n",
      "30 articles downloaded from marketwatch , url:  https://www.theguardian.com/world/2020/may/20/ukraine-joe-biden-petro-poroshenko-recordings-investigation\n",
      "40 articles downloaded from marketwatch , url:  https://www.theguardian.com/music/2020/may/20/joni-mitchell-where-to-start-in-her-back-catalogue\n",
      "50 articles downloaded from marketwatch , url:  https://www.theguardian.com/sport/blog/2020/may/20/cricket-obsession-ball-shines-saliva-icc-covid-19\n",
      "Downloading articles from  fox_business_latest_headlines\n",
      "10 articles downloaded from fox_business_latest_headlines , url:  https://www.foxnews.com/media/greg-gutfeld-media-coverage-biden-campaign-homebound\n",
      "Downloading articles from  fox_business_opinion\n",
      "10 articles downloaded from fox_business_opinion , url:  http://feeds.foxnews.com/~r/foxnews/opinion/~3/gWo9Y4uv6Vk/ali-pardo-trump-supports-freedom-for-cuban-people-while-biden-appeases-castro-dictatorship\n",
      "20 articles downloaded from fox_business_opinion , url:  http://feeds.foxnews.com/~r/foxnews/opinion/~3/6ZwDcCn6x6E/ravi-zacharias-lauren-green-christian-leader-death\n",
      "Downloading articles from  entrepreneur_latest\n",
      "10 articles downloaded from entrepreneur_latest , url:  http://feedproxy.google.com/~r/entrepreneur/latest/~3/KyzvR4ePXIo/350889\n",
      "Downloading articles from  entrepreneur_marketing\n",
      "10 articles downloaded from entrepreneur_marketing , url:  http://feedproxy.google.com/~r/entrepreneur/salesandmarketing/~3/9wLAEwCksVk/349181\n",
      "Downloading articles from  reuters_money\n",
      "10 articles downloaded from reuters_money , url:  http://feeds.reuters.com/~r/news/wealth/~3/IWqsRgBNBWw/us-money-market-assets-increased-in-latest-week-imoneynet-idUSKBN22I2W8\n",
      "20 articles downloaded from reuters_money , url:  http://feeds.reuters.com/~r/news/wealth/~3/EoRcSLX0hgs/some-u-s-fund-managers-risk-long-term-bets-on-tanking-oil-sector-idUSKCN22334G\n",
      "Downloading articles from  reuters_science\n",
      "10 articles downloaded from reuters_science , url:  http://feeds.reuters.com/~r/reuters/scienceNews/~3/CVVDV1M_5Ok/enzyme-makes-men-more-vulnerable-to-coronavirus-adding-interferon-may-improve-treatment-idUSKBN22N2J9\n",
      "20 articles downloaded from reuters_science , url:  http://feeds.reuters.com/~r/reuters/scienceNews/~3/8jIztqhbTwk/exclusive-trump-administration-drafting-artemis-accords-pact-for-moon-mining-sources-idUSKBN22H2SB\n",
      "Downloading articles from  sciencedaily\n",
      "10 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200520124956.htm\n",
      "20 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200520084123.htm\n",
      "30 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200519165844.htm\n",
      "40 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200519144404.htm\n",
      "50 articles downloaded from sciencedaily , url:  https://www.sciencedaily.com/releases/2020/05/200519114239.htm\n",
      "Downloading articles from  economist_business\n",
      "Downloading articles from  economist_science_and_tech\n",
      "Downloading articles from  fivethirtyeight_science\n",
      "10 articles downloaded from fivethirtyeight_science , url:  https://fivethirtyeight.com/features/infectious-disease-experts-think-texas-will-see-an-increase-in-cases/\n",
      "20 articles downloaded from fivethirtyeight_science , url:  https://fivethirtyeight.com/features/one-chart-isnt-going-to-tell-you-when-the-pandemic-peaked/\n",
      "Downloading articles from  fivethirtyeight_economics\n",
      "10 articles downloaded from fivethirtyeight_economics , url:  https://fivethirtyeight.com/features/the-americans-who-suffered-when-the-economy-shut-down-are-also-in-more-danger-as-it-reopens/\n",
      "20 articles downloaded from fivethirtyeight_economics , url:  https://fivethirtyeight.com/features/more-than-16-million-americans-have-lost-their-jobs-in-the-past-three-weeks/\n",
      "Downloading articles from  nbpostgazette\n",
      "10 articles downloaded from nbpostgazette , url:  https://nbpostgazette.com/world-laughter-day-history-significance-facts-benefits-quotes-greetings-messages/?utm_source=rss&utm_medium=rss&utm_campaign=world-laughter-day-history-significance-facts-benefits-quotes-greetings-messages\n",
      "Downloading articles from  journalismday\n",
      "10 articles downloaded from journalismday , url:  https://journalismday.com/2017/07/global-microtomes-market-2/\n",
      "Downloading articles from  satprnews\n",
      "10 articles downloaded from satprnews , url:  https://satprnews.com/2020/05/12/exoplanet-hunter-takes-its-first-photo/\n",
      "Downloading articles from  insidertradings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading articles from  truthfulreporter\n",
      "Downloading articles from  highlandmirror\n",
      "Downloading articles from  thefinancialanalyst\n",
      "Downloading articles from  reportagestuff\n",
      "Downloading articles from  tokenfolks\n",
      "Downloading articles from  heraldanalyst\n",
      "Downloading articles from  findmarketresearch\n",
      "saving articles . . . in scraped_articles.json\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "# Iterate through each news company\n",
    "# the company is the name, the value is the dictionary of links\n",
    "for company, value in companies.items():\n",
    "    # If a RSS link is provided in the JSON file, this will be the first choice.\n",
    "    # Reason for this is that, RSS feeds often give more consistent and correct data.\n",
    "    # If you do not want to scrape from the RSS-feed, just leave the RSS attr empty in the JSON file.\n",
    "    if 'rss' in value:\n",
    "        d = fp.parse(value['rss'])\n",
    "        print(\"Downloading articles from \", company)\n",
    "        newsPaper = {\n",
    "            \"rss\": value['rss'],\n",
    "            \"link\": value['link'],\n",
    "            \"articles\": []\n",
    "        }\n",
    "        for entry in d.entries:\n",
    "            # Check if publish date is provided, if no the article is skipped.\n",
    "            # This is done to keep consistency in the data and to keep the script from crashing.\n",
    "            if hasattr(entry, 'published'):\n",
    "                if count > LIMIT:\n",
    "                    break\n",
    "                article = {}\n",
    "                article['link'] = entry.link\n",
    "                date = entry.published_parsed\n",
    "                article['published'] = datetime.fromtimestamp(mktime(date)).isoformat()\n",
    "                try:\n",
    "                    content = Article(entry.link)\n",
    "                    content.download()\n",
    "                    content.parse()\n",
    "                except Exception as e:\n",
    "                    # If the download for some reason fails (ex. 404) the script will continue downloading\n",
    "                    # the next article.\n",
    "                    print(e)\n",
    "                    print(\"continuing...\")\n",
    "                    continue\n",
    "                article['title'] = content.title\n",
    "                article['text'] = content.text\n",
    "                article['author'] = content.authors\n",
    "                newsPaper['articles'].append(article)\n",
    "                if count % 10 == 0:\n",
    "                    print(count, \"articles downloaded from\", company, \", url: \", entry.link)\n",
    "                count = count + 1\n",
    "    else:\n",
    "        # This is the fallback method if a RSS-feed link is not provided.\n",
    "        # It uses the python newspaper library to extract articles\n",
    "        print(\"Building site for \", company)\n",
    "        paper = newspaper.build(value['link'], memoize_articles=False)\n",
    "        newsPaper = {\n",
    "            \"link\": value['link'],\n",
    "            \"articles\": []\n",
    "        }\n",
    "        noneTypeCount = 0\n",
    "        for content in paper.articles:\n",
    "            if count > LIMIT:\n",
    "                break\n",
    "            try:\n",
    "                content.download()\n",
    "                content.parse()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"continuing...\")\n",
    "                continue\n",
    "            # Again, for consistency, if there is no found publish date the article will be skipped.\n",
    "            # After 10 downloaded articles from the same newspaper without publish date, the company will be skipped.\n",
    "            if content.publish_date is None:\n",
    "                print(count, \" Article has date of type None...\")\n",
    "                noneTypeCount = noneTypeCount + 1\n",
    "                if noneTypeCount > 10:\n",
    "                    print(\"Too many noneType dates, aborting...\")\n",
    "                    noneTypeCount = 0\n",
    "                    break\n",
    "                count = count + 1\n",
    "                continue\n",
    "            article = {}\n",
    "            article['title'] = content.title\n",
    "            article['text'] = content.text\n",
    "            article['link'] = content.url\n",
    "            article['published'] = content.publish_date.isoformat()\n",
    "            article['author'] = content.authors\n",
    "            newsPaper['articles'].append(article)\n",
    "            if count % 10 == 0: \n",
    "                print(count, \"articles downloaded from\", company, \" using newspaper, url: \", content.url)\n",
    "            count = count + 1\n",
    "            noneTypeCount = 0\n",
    "    count = 1\n",
    "    data['newspapers'][company] = newsPaper\n",
    "\n",
    "\n",
    "# Finally it saves the articles as a JSON-file.\n",
    "try:\n",
    "    fname = 'scraped_articles.json'\n",
    "    print('saving articles . . . in {}'.format(fname))\n",
    "    with open(fname, 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "except Exception as e: print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
