{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPrev</th>\n",
       "      <th>BStreak</th>\n",
       "      <th>B_Age</th>\n",
       "      <th>B_Height</th>\n",
       "      <th>B_HomeTown</th>\n",
       "      <th>B_ID</th>\n",
       "      <th>B_Location</th>\n",
       "      <th>B_Name</th>\n",
       "      <th>B_Weight</th>\n",
       "      <th>B__Round1_Grappling_Reversals_Landed</th>\n",
       "      <th>...</th>\n",
       "      <th>R__Round5_TIP_Ground Time</th>\n",
       "      <th>R__Round5_TIP_Guard Control Time</th>\n",
       "      <th>R__Round5_TIP_Half Guard Control Time</th>\n",
       "      <th>R__Round5_TIP_Misc. Ground Control Time</th>\n",
       "      <th>R__Round5_TIP_Mount Control Time</th>\n",
       "      <th>R__Round5_TIP_Neutral Time</th>\n",
       "      <th>R__Round5_TIP_Side Control Time</th>\n",
       "      <th>R__Round5_TIP_Standing Time</th>\n",
       "      <th>winby</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Trento Italy</td>\n",
       "      <td>2783</td>\n",
       "      <td>Mezzocorona Italy</td>\n",
       "      <td>Marvin Vettori</td>\n",
       "      <td>84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEC</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Careiro da Várzea, Amazonas Brazil</td>\n",
       "      <td>2208</td>\n",
       "      <td>Pharr, Texas USA</td>\n",
       "      <td>Carlos Diego Ferreira</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUB</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>Kanagawa Japan</td>\n",
       "      <td>721</td>\n",
       "      <td>Tokyo Japan</td>\n",
       "      <td>Takanori Gomi</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Tijuana Mexico</td>\n",
       "      <td>2825</td>\n",
       "      <td>Tijuana Mexico</td>\n",
       "      <td>Brandon Moreno</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUB</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>Spokane, WA USA</td>\n",
       "      <td>2260</td>\n",
       "      <td>Spokane, WA USA</td>\n",
       "      <td>Elizabeth Phillips</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEC</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 895 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BPrev  BStreak  B_Age  B_Height                          B_HomeTown  B_ID  \\\n",
       "0      1        1   23.0     182.0                        Trento Italy  2783   \n",
       "1      0        0   32.0     175.0  Careiro da Várzea, Amazonas Brazil  2208   \n",
       "2      2        0   38.0     172.0                      Kanagawa Japan   721   \n",
       "3      0        0   23.0     170.0                      Tijuana Mexico  2825   \n",
       "4      3        1   30.0     167.0                     Spokane, WA USA  2260   \n",
       "\n",
       "          B_Location                 B_Name  B_Weight  \\\n",
       "0  Mezzocorona Italy         Marvin Vettori        84   \n",
       "1   Pharr, Texas USA  Carlos Diego Ferreira        70   \n",
       "2        Tokyo Japan          Takanori Gomi        70   \n",
       "3     Tijuana Mexico         Brandon Moreno        56   \n",
       "4    Spokane, WA USA     Elizabeth Phillips        61   \n",
       "\n",
       "   B__Round1_Grappling_Reversals_Landed  ...  R__Round5_TIP_Ground Time  \\\n",
       "0                                   0.0  ...                        NaN   \n",
       "1                                   NaN  ...                        NaN   \n",
       "2                                   0.0  ...                        NaN   \n",
       "3                                   NaN  ...                        NaN   \n",
       "4                                   0.0  ...                        NaN   \n",
       "\n",
       "   R__Round5_TIP_Guard Control Time  R__Round5_TIP_Half Guard Control Time  \\\n",
       "0                               NaN                                    NaN   \n",
       "1                               NaN                                    NaN   \n",
       "2                               NaN                                    NaN   \n",
       "3                               NaN                                    NaN   \n",
       "4                               NaN                                    NaN   \n",
       "\n",
       "   R__Round5_TIP_Misc. Ground Control Time  R__Round5_TIP_Mount Control Time  \\\n",
       "0                                      NaN                               NaN   \n",
       "1                                      NaN                               NaN   \n",
       "2                                      NaN                               NaN   \n",
       "3                                      NaN                               NaN   \n",
       "4                                      NaN                               NaN   \n",
       "\n",
       "   R__Round5_TIP_Neutral Time  R__Round5_TIP_Side Control Time  \\\n",
       "0                         NaN                              NaN   \n",
       "1                         NaN                              NaN   \n",
       "2                         NaN                              NaN   \n",
       "3                         NaN                              NaN   \n",
       "4                         NaN                              NaN   \n",
       "\n",
       "   R__Round5_TIP_Standing Time   winby  winner  \n",
       "0                          NaN     DEC     red  \n",
       "1                          NaN     SUB    blue  \n",
       "2                          NaN  KO/TKO     red  \n",
       "3                          NaN     SUB    blue  \n",
       "4                          NaN     DEC     red  \n",
       "\n",
       "[5 rows x 895 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "ufc = pd.read_csv(\"resources\\data.csv\")\n",
    "ufc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPrev                              1477\n",
       "BStreak                            1477\n",
       "B_Age                              1474\n",
       "B_Height                           1476\n",
       "B_HomeTown                         1471\n",
       "                                   ... \n",
       "R__Round5_TIP_Neutral Time          144\n",
       "R__Round5_TIP_Side Control Time     144\n",
       "R__Round5_TIP_Standing Time         144\n",
       "winby                              1461\n",
       "winner                             1477\n",
       "Length: 895, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPrev</th>\n",
       "      <th>BStreak</th>\n",
       "      <th>B_Age</th>\n",
       "      <th>B_Height</th>\n",
       "      <th>B_HomeTown</th>\n",
       "      <th>B_ID</th>\n",
       "      <th>B_Location</th>\n",
       "      <th>B_Name</th>\n",
       "      <th>B_Weight</th>\n",
       "      <th>B__Round1_Grappling_Reversals_Landed</th>\n",
       "      <th>...</th>\n",
       "      <th>R__Round5_TIP_Ground Time</th>\n",
       "      <th>R__Round5_TIP_Guard Control Time</th>\n",
       "      <th>R__Round5_TIP_Half Guard Control Time</th>\n",
       "      <th>R__Round5_TIP_Misc. Ground Control Time</th>\n",
       "      <th>R__Round5_TIP_Mount Control Time</th>\n",
       "      <th>R__Round5_TIP_Neutral Time</th>\n",
       "      <th>R__Round5_TIP_Side Control Time</th>\n",
       "      <th>R__Round5_TIP_Standing Time</th>\n",
       "      <th>winby</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>Trento Italy</td>\n",
       "      <td>2783</td>\n",
       "      <td>Mezzocorona Italy</td>\n",
       "      <td>Marvin Vettori</td>\n",
       "      <td>84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEC</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Careiro da Várzea, Amazonas Brazil</td>\n",
       "      <td>2208</td>\n",
       "      <td>Pharr, Texas USA</td>\n",
       "      <td>Carlos Diego Ferreira</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUB</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>Kanagawa Japan</td>\n",
       "      <td>721</td>\n",
       "      <td>Tokyo Japan</td>\n",
       "      <td>Takanori Gomi</td>\n",
       "      <td>70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KO/TKO</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Tijuana Mexico</td>\n",
       "      <td>2825</td>\n",
       "      <td>Tijuana Mexico</td>\n",
       "      <td>Brandon Moreno</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUB</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>Spokane, WA USA</td>\n",
       "      <td>2260</td>\n",
       "      <td>Spokane, WA USA</td>\n",
       "      <td>Elizabeth Phillips</td>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEC</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 895 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BPrev  BStreak  B_Age  B_Height                          B_HomeTown  B_ID  \\\n",
       "0      1        1   23.0     182.0                        Trento Italy  2783   \n",
       "1      0        0   32.0     175.0  Careiro da Várzea, Amazonas Brazil  2208   \n",
       "2      2        0   38.0     172.0                      Kanagawa Japan   721   \n",
       "3      0        0   23.0     170.0                      Tijuana Mexico  2825   \n",
       "4      3        1   30.0     167.0                     Spokane, WA USA  2260   \n",
       "\n",
       "          B_Location                 B_Name  B_Weight  \\\n",
       "0  Mezzocorona Italy         Marvin Vettori        84   \n",
       "1   Pharr, Texas USA  Carlos Diego Ferreira        70   \n",
       "2        Tokyo Japan          Takanori Gomi        70   \n",
       "3     Tijuana Mexico         Brandon Moreno        56   \n",
       "4    Spokane, WA USA     Elizabeth Phillips        61   \n",
       "\n",
       "   B__Round1_Grappling_Reversals_Landed  ...  R__Round5_TIP_Ground Time  \\\n",
       "0                                   0.0  ...                        NaN   \n",
       "1                                   NaN  ...                        NaN   \n",
       "2                                   0.0  ...                        NaN   \n",
       "3                                   NaN  ...                        NaN   \n",
       "4                                   0.0  ...                        NaN   \n",
       "\n",
       "   R__Round5_TIP_Guard Control Time  R__Round5_TIP_Half Guard Control Time  \\\n",
       "0                               NaN                                    NaN   \n",
       "1                               NaN                                    NaN   \n",
       "2                               NaN                                    NaN   \n",
       "3                               NaN                                    NaN   \n",
       "4                               NaN                                    NaN   \n",
       "\n",
       "   R__Round5_TIP_Misc. Ground Control Time  R__Round5_TIP_Mount Control Time  \\\n",
       "0                                      NaN                               NaN   \n",
       "1                                      NaN                               NaN   \n",
       "2                                      NaN                               NaN   \n",
       "3                                      NaN                               NaN   \n",
       "4                                      NaN                               NaN   \n",
       "\n",
       "   R__Round5_TIP_Neutral Time  R__Round5_TIP_Side Control Time  \\\n",
       "0                         NaN                              NaN   \n",
       "1                         NaN                              NaN   \n",
       "2                         NaN                              NaN   \n",
       "3                         NaN                              NaN   \n",
       "4                         NaN                              NaN   \n",
       "\n",
       "   R__Round5_TIP_Standing Time   winby  winner  \n",
       "0                          NaN     DEC     red  \n",
       "1                          NaN     SUB    blue  \n",
       "2                          NaN  KO/TKO     red  \n",
       "3                          NaN     SUB    blue  \n",
       "4                          NaN     DEC     red  \n",
       "\n",
       "[5 rows x 895 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufc = ufc[ufc.winner != 'no contest']\n",
    "ufc = ufc[ufc.winner != 'draw']\n",
    "#ufc_zero = ufc.fillna(0)\n",
    "ufc_zero = ufc.copy()\n",
    "ufc_zero.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idealcol = ['BPrev','BStreak','B_Age','B_Height','B_Weight','RPrev','RStreak','R_Age','R_Height','R_Weight','winner']\n",
    "ufc_filtered = ufc_zero[idealcol].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ufc_filtered[\"winner\"]= ufc_filtered[\"winner\"].replace(\"red\", 0)\n",
    "#ufc_filtered[\"winner\"]= ufc_filtered[\"winner\"].replace(\"blue\", 1)\n",
    "#ufc_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPrev       1451\n",
       "BStreak     1451\n",
       "B_Age       1448\n",
       "B_Height    1450\n",
       "B_Weight    1451\n",
       "RPrev       1451\n",
       "RStreak     1451\n",
       "R_Age       1450\n",
       "R_Height    1451\n",
       "R_Weight    1451\n",
       "winner      1451\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufc_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_filtered['BPrev'] = ufc_filtered['BPrev'].fillna(np.mean(ufc_filtered['BPrev']))\n",
    "ufc_filtered['BStreak'] = ufc_filtered['BStreak'].fillna(np.mean(ufc_filtered['BStreak']))\n",
    "ufc_filtered['B_Age'] = ufc_filtered['B_Age'].fillna(np.mean(ufc_filtered['B_Age']))\n",
    "ufc_filtered['B_Height'] = ufc_filtered['B_Height'].fillna(np.mean(ufc_filtered['B_Height']))\n",
    "ufc_filtered['B_Weight'] = ufc_filtered['B_Weight'].fillna(np.mean(ufc_filtered['B_Weight']))\n",
    "ufc_filtered['RPrev'] = ufc_filtered['RPrev'].fillna(np.mean(ufc_filtered['RPrev']))\n",
    "ufc_filtered['RStreak'] = ufc_filtered['RStreak'].fillna(np.mean(ufc_filtered['RStreak']))\n",
    "ufc_filtered['R_Age'] = ufc_filtered['R_Age'].fillna(np.mean(ufc_filtered['R_Age']))\n",
    "ufc_filtered['R_Height'] = ufc_filtered['R_Height'].fillna(np.mean(ufc_filtered['R_Height']))\n",
    "ufc_filtered['R_Weight'] = ufc_filtered['R_Weight'].fillna(np.mean(ufc_filtered['R_Weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BPrev       1451\n",
       "BStreak     1451\n",
       "B_Age       1451\n",
       "B_Height    1451\n",
       "B_Weight    1451\n",
       "RPrev       1451\n",
       "RStreak     1451\n",
       "R_Age       1451\n",
       "R_Height    1451\n",
       "R_Weight    1451\n",
       "winner      1451\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufc_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['BPrev','BStreak','B_Age','B_Height','B_Weight','RPrev','RStreak','R_Age','R_Height','R_Weight']\n",
    "X = ufc_filtered[feature_cols] # Features\n",
    "y = ufc_filtered.winner # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_y_train = le.transform(y_train)\n",
    "le_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_y_test = le.transform(y_test)\n",
    "le_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(le_y_train)\n",
    "y_test_categorical = to_categorical(le_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=6, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 14        \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1015 samples\n",
      "Epoch 1/100\n",
      "1015/1015 - 1s - loss: 0.7154 - accuracy: 0.5586\n",
      "Epoch 2/100\n",
      "1015/1015 - 0s - loss: 0.7016 - accuracy: 0.5744\n",
      "Epoch 3/100\n",
      "1015/1015 - 0s - loss: 0.6919 - accuracy: 0.5744\n",
      "Epoch 4/100\n",
      "1015/1015 - 0s - loss: 0.6848 - accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "1015/1015 - 0s - loss: 0.6793 - accuracy: 0.5744\n",
      "Epoch 6/100\n",
      "1015/1015 - 0s - loss: 0.6742 - accuracy: 0.5823\n",
      "Epoch 7/100\n",
      "1015/1015 - 0s - loss: 0.6705 - accuracy: 0.5793\n",
      "Epoch 8/100\n",
      "1015/1015 - 0s - loss: 0.6668 - accuracy: 0.5862\n",
      "Epoch 9/100\n",
      "1015/1015 - 0s - loss: 0.6642 - accuracy: 0.5911\n",
      "Epoch 10/100\n",
      "1015/1015 - 0s - loss: 0.6617 - accuracy: 0.5921\n",
      "Epoch 11/100\n",
      "1015/1015 - 0s - loss: 0.6591 - accuracy: 0.5951\n",
      "Epoch 12/100\n",
      "1015/1015 - 0s - loss: 0.6572 - accuracy: 0.5980\n",
      "Epoch 13/100\n",
      "1015/1015 - 0s - loss: 0.6558 - accuracy: 0.6020\n",
      "Epoch 14/100\n",
      "1015/1015 - 0s - loss: 0.6542 - accuracy: 0.6020\n",
      "Epoch 15/100\n",
      "1015/1015 - 0s - loss: 0.6528 - accuracy: 0.6059\n",
      "Epoch 16/100\n",
      "1015/1015 - 0s - loss: 0.6515 - accuracy: 0.6059\n",
      "Epoch 17/100\n",
      "1015/1015 - 0s - loss: 0.6502 - accuracy: 0.6049\n",
      "Epoch 18/100\n",
      "1015/1015 - 0s - loss: 0.6491 - accuracy: 0.6069\n",
      "Epoch 19/100\n",
      "1015/1015 - 0s - loss: 0.6482 - accuracy: 0.6089\n",
      "Epoch 20/100\n",
      "1015/1015 - 0s - loss: 0.6472 - accuracy: 0.6128\n",
      "Epoch 21/100\n",
      "1015/1015 - 0s - loss: 0.6464 - accuracy: 0.6167\n",
      "Epoch 22/100\n",
      "1015/1015 - 0s - loss: 0.6458 - accuracy: 0.6167\n",
      "Epoch 23/100\n",
      "1015/1015 - 0s - loss: 0.6449 - accuracy: 0.6177\n",
      "Epoch 24/100\n",
      "1015/1015 - 0s - loss: 0.6442 - accuracy: 0.6177\n",
      "Epoch 25/100\n",
      "1015/1015 - 0s - loss: 0.6436 - accuracy: 0.6187\n",
      "Epoch 26/100\n",
      "1015/1015 - 0s - loss: 0.6427 - accuracy: 0.6256\n",
      "Epoch 27/100\n",
      "1015/1015 - 0s - loss: 0.6421 - accuracy: 0.6236\n",
      "Epoch 28/100\n",
      "1015/1015 - 0s - loss: 0.6416 - accuracy: 0.6266\n",
      "Epoch 29/100\n",
      "1015/1015 - 0s - loss: 0.6407 - accuracy: 0.6296\n",
      "Epoch 30/100\n",
      "1015/1015 - 0s - loss: 0.6403 - accuracy: 0.6286\n",
      "Epoch 31/100\n",
      "1015/1015 - 0s - loss: 0.6395 - accuracy: 0.6325\n",
      "Epoch 32/100\n",
      "1015/1015 - 0s - loss: 0.6391 - accuracy: 0.6335\n",
      "Epoch 33/100\n",
      "1015/1015 - 0s - loss: 0.6384 - accuracy: 0.6325\n",
      "Epoch 34/100\n",
      "1015/1015 - 0s - loss: 0.6385 - accuracy: 0.6355\n",
      "Epoch 35/100\n",
      "1015/1015 - 0s - loss: 0.6374 - accuracy: 0.6345\n",
      "Epoch 36/100\n",
      "1015/1015 - 0s - loss: 0.6376 - accuracy: 0.6345\n",
      "Epoch 37/100\n",
      "1015/1015 - 0s - loss: 0.6367 - accuracy: 0.6315\n",
      "Epoch 38/100\n",
      "1015/1015 - 0s - loss: 0.6365 - accuracy: 0.6325\n",
      "Epoch 39/100\n",
      "1015/1015 - 0s - loss: 0.6360 - accuracy: 0.6315\n",
      "Epoch 40/100\n",
      "1015/1015 - 0s - loss: 0.6363 - accuracy: 0.6345\n",
      "Epoch 41/100\n",
      "1015/1015 - 0s - loss: 0.6357 - accuracy: 0.6355\n",
      "Epoch 42/100\n",
      "1015/1015 - 0s - loss: 0.6353 - accuracy: 0.6374\n",
      "Epoch 43/100\n",
      "1015/1015 - 0s - loss: 0.6353 - accuracy: 0.6374\n",
      "Epoch 44/100\n",
      "1015/1015 - 0s - loss: 0.6348 - accuracy: 0.6414\n",
      "Epoch 45/100\n",
      "1015/1015 - 0s - loss: 0.6347 - accuracy: 0.6365\n",
      "Epoch 46/100\n",
      "1015/1015 - 0s - loss: 0.6344 - accuracy: 0.6404\n",
      "Epoch 47/100\n",
      "1015/1015 - 0s - loss: 0.6341 - accuracy: 0.6394\n",
      "Epoch 48/100\n",
      "1015/1015 - 0s - loss: 0.6341 - accuracy: 0.6443\n",
      "Epoch 49/100\n",
      "1015/1015 - 0s - loss: 0.6338 - accuracy: 0.6404\n",
      "Epoch 50/100\n",
      "1015/1015 - 0s - loss: 0.6337 - accuracy: 0.6394\n",
      "Epoch 51/100\n",
      "1015/1015 - 0s - loss: 0.6336 - accuracy: 0.6404\n",
      "Epoch 52/100\n",
      "1015/1015 - 0s - loss: 0.6332 - accuracy: 0.6404\n",
      "Epoch 53/100\n",
      "1015/1015 - 0s - loss: 0.6335 - accuracy: 0.6433\n",
      "Epoch 54/100\n",
      "1015/1015 - 0s - loss: 0.6331 - accuracy: 0.6404\n",
      "Epoch 55/100\n",
      "1015/1015 - 0s - loss: 0.6330 - accuracy: 0.6394\n",
      "Epoch 56/100\n",
      "1015/1015 - 0s - loss: 0.6326 - accuracy: 0.6414\n",
      "Epoch 57/100\n",
      "1015/1015 - 0s - loss: 0.6333 - accuracy: 0.6463\n",
      "Epoch 58/100\n",
      "1015/1015 - 0s - loss: 0.6324 - accuracy: 0.6384\n",
      "Epoch 59/100\n",
      "1015/1015 - 0s - loss: 0.6321 - accuracy: 0.6414\n",
      "Epoch 60/100\n",
      "1015/1015 - 0s - loss: 0.6318 - accuracy: 0.6414\n",
      "Epoch 61/100\n",
      "1015/1015 - 0s - loss: 0.6324 - accuracy: 0.6355\n",
      "Epoch 62/100\n",
      "1015/1015 - 0s - loss: 0.6318 - accuracy: 0.6414\n",
      "Epoch 63/100\n",
      "1015/1015 - 0s - loss: 0.6321 - accuracy: 0.6384\n",
      "Epoch 64/100\n",
      "1015/1015 - 0s - loss: 0.6313 - accuracy: 0.6394\n",
      "Epoch 65/100\n",
      "1015/1015 - 0s - loss: 0.6311 - accuracy: 0.6365\n",
      "Epoch 66/100\n",
      "1015/1015 - 0s - loss: 0.6308 - accuracy: 0.6384\n",
      "Epoch 67/100\n",
      "1015/1015 - 0s - loss: 0.6308 - accuracy: 0.6365\n",
      "Epoch 68/100\n",
      "1015/1015 - 0s - loss: 0.6308 - accuracy: 0.6384\n",
      "Epoch 69/100\n",
      "1015/1015 - 0s - loss: 0.6304 - accuracy: 0.6414\n",
      "Epoch 70/100\n",
      "1015/1015 - 0s - loss: 0.6300 - accuracy: 0.6365\n",
      "Epoch 71/100\n",
      "1015/1015 - 0s - loss: 0.6301 - accuracy: 0.6374\n",
      "Epoch 72/100\n",
      "1015/1015 - 0s - loss: 0.6298 - accuracy: 0.6365\n",
      "Epoch 73/100\n",
      "1015/1015 - 0s - loss: 0.6295 - accuracy: 0.6443\n",
      "Epoch 74/100\n",
      "1015/1015 - 0s - loss: 0.6291 - accuracy: 0.6443\n",
      "Epoch 75/100\n",
      "1015/1015 - 0s - loss: 0.6291 - accuracy: 0.6424\n",
      "Epoch 76/100\n",
      "1015/1015 - 0s - loss: 0.6297 - accuracy: 0.6414\n",
      "Epoch 77/100\n",
      "1015/1015 - 0s - loss: 0.6287 - accuracy: 0.6443\n",
      "Epoch 78/100\n",
      "1015/1015 - 0s - loss: 0.6286 - accuracy: 0.6404\n",
      "Epoch 79/100\n",
      "1015/1015 - 0s - loss: 0.6285 - accuracy: 0.6433\n",
      "Epoch 80/100\n",
      "1015/1015 - 0s - loss: 0.6281 - accuracy: 0.6443\n",
      "Epoch 81/100\n",
      "1015/1015 - 0s - loss: 0.6285 - accuracy: 0.6424\n",
      "Epoch 82/100\n",
      "1015/1015 - 0s - loss: 0.6276 - accuracy: 0.6414\n",
      "Epoch 83/100\n",
      "1015/1015 - 0s - loss: 0.6279 - accuracy: 0.6483\n",
      "Epoch 84/100\n",
      "1015/1015 - 0s - loss: 0.6276 - accuracy: 0.6443\n",
      "Epoch 85/100\n",
      "1015/1015 - 0s - loss: 0.6279 - accuracy: 0.6414\n",
      "Epoch 86/100\n",
      "1015/1015 - 0s - loss: 0.6272 - accuracy: 0.6463\n",
      "Epoch 87/100\n",
      "1015/1015 - 0s - loss: 0.6273 - accuracy: 0.6453\n",
      "Epoch 88/100\n",
      "1015/1015 - 0s - loss: 0.6271 - accuracy: 0.6443\n",
      "Epoch 89/100\n",
      "1015/1015 - 0s - loss: 0.6274 - accuracy: 0.6433\n",
      "Epoch 90/100\n",
      "1015/1015 - 0s - loss: 0.6274 - accuracy: 0.6433\n",
      "Epoch 91/100\n",
      "1015/1015 - 0s - loss: 0.6268 - accuracy: 0.6424\n",
      "Epoch 92/100\n",
      "1015/1015 - 0s - loss: 0.6265 - accuracy: 0.6453\n",
      "Epoch 93/100\n",
      "1015/1015 - 0s - loss: 0.6268 - accuracy: 0.6483\n",
      "Epoch 94/100\n",
      "1015/1015 - 0s - loss: 0.6263 - accuracy: 0.6483\n",
      "Epoch 95/100\n",
      "1015/1015 - 0s - loss: 0.6267 - accuracy: 0.6443\n",
      "Epoch 96/100\n",
      "1015/1015 - 0s - loss: 0.6265 - accuracy: 0.6483\n",
      "Epoch 97/100\n",
      "1015/1015 - 0s - loss: 0.6262 - accuracy: 0.6453\n",
      "Epoch 98/100\n",
      "1015/1015 - 0s - loss: 0.6261 - accuracy: 0.6473\n",
      "Epoch 99/100\n",
      "1015/1015 - 0s - loss: 0.6260 - accuracy: 0.6483\n",
      "Epoch 100/100\n",
      "1015/1015 - 0s - loss: 0.6259 - accuracy: 0.6473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebfeb21208>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100, # should be 100\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model\\model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model\\model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import model_from_json \n",
    "\n",
    "# opening and store file in a variable\n",
    "json_file = open('model\\model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Keras model_from_json to make a loaded model\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awesome, your model has been loaded from disk! Cool beans!\n"
     ]
    }
   ],
   "source": [
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model\\model.h5\")\n",
    "print(\"Awesome, your model has been loaded from disk! Cool beans!\")\n",
    "\n",
    "# compile and evaluate loaded model\n",
    "loaded_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=6, activation='relu', input_dim=10))\n",
    "#deep_model.add(Dense(units=6, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1015 samples\n",
      "Epoch 1/100\n",
      "1015/1015 - 1s - loss: 0.7633 - accuracy: 0.5300\n",
      "Epoch 2/100\n",
      "1015/1015 - 0s - loss: 0.7267 - accuracy: 0.5576\n",
      "Epoch 3/100\n",
      "1015/1015 - 0s - loss: 0.7087 - accuracy: 0.5645\n",
      "Epoch 4/100\n",
      "1015/1015 - 0s - loss: 0.6995 - accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "1015/1015 - 0s - loss: 0.6934 - accuracy: 0.5793\n",
      "Epoch 6/100\n",
      "1015/1015 - 0s - loss: 0.6886 - accuracy: 0.5793\n",
      "Epoch 7/100\n",
      "1015/1015 - 0s - loss: 0.6839 - accuracy: 0.5833\n",
      "Epoch 8/100\n",
      "1015/1015 - 0s - loss: 0.6798 - accuracy: 0.5793\n",
      "Epoch 9/100\n",
      "1015/1015 - 0s - loss: 0.6766 - accuracy: 0.5842\n",
      "Epoch 10/100\n",
      "1015/1015 - 0s - loss: 0.6734 - accuracy: 0.5921\n",
      "Epoch 11/100\n",
      "1015/1015 - 0s - loss: 0.6712 - accuracy: 0.5901\n",
      "Epoch 12/100\n",
      "1015/1015 - 0s - loss: 0.6687 - accuracy: 0.5961\n",
      "Epoch 13/100\n",
      "1015/1015 - 0s - loss: 0.6662 - accuracy: 0.5990\n",
      "Epoch 14/100\n",
      "1015/1015 - 0s - loss: 0.6647 - accuracy: 0.5921\n",
      "Epoch 15/100\n",
      "1015/1015 - 0s - loss: 0.6629 - accuracy: 0.5970\n",
      "Epoch 16/100\n",
      "1015/1015 - 0s - loss: 0.6613 - accuracy: 0.5990\n",
      "Epoch 17/100\n",
      "1015/1015 - 0s - loss: 0.6602 - accuracy: 0.6010\n",
      "Epoch 18/100\n",
      "1015/1015 - 0s - loss: 0.6587 - accuracy: 0.6020\n",
      "Epoch 19/100\n",
      "1015/1015 - 0s - loss: 0.6572 - accuracy: 0.6039\n",
      "Epoch 20/100\n",
      "1015/1015 - 0s - loss: 0.6562 - accuracy: 0.6079\n",
      "Epoch 21/100\n",
      "1015/1015 - 0s - loss: 0.6551 - accuracy: 0.6079\n",
      "Epoch 22/100\n",
      "1015/1015 - 0s - loss: 0.6539 - accuracy: 0.6128\n",
      "Epoch 23/100\n",
      "1015/1015 - 0s - loss: 0.6530 - accuracy: 0.6118\n",
      "Epoch 24/100\n",
      "1015/1015 - 0s - loss: 0.6519 - accuracy: 0.6128\n",
      "Epoch 25/100\n",
      "1015/1015 - 0s - loss: 0.6513 - accuracy: 0.6167\n",
      "Epoch 26/100\n",
      "1015/1015 - 0s - loss: 0.6503 - accuracy: 0.6128\n",
      "Epoch 27/100\n",
      "1015/1015 - 0s - loss: 0.6499 - accuracy: 0.6148\n",
      "Epoch 28/100\n",
      "1015/1015 - 0s - loss: 0.6492 - accuracy: 0.6177\n",
      "Epoch 29/100\n",
      "1015/1015 - 0s - loss: 0.6487 - accuracy: 0.6217\n",
      "Epoch 30/100\n",
      "1015/1015 - 0s - loss: 0.6483 - accuracy: 0.6177\n",
      "Epoch 31/100\n",
      "1015/1015 - 0s - loss: 0.6477 - accuracy: 0.6207\n",
      "Epoch 32/100\n",
      "1015/1015 - 0s - loss: 0.6475 - accuracy: 0.6217\n",
      "Epoch 33/100\n",
      "1015/1015 - 0s - loss: 0.6465 - accuracy: 0.6207\n",
      "Epoch 34/100\n",
      "1015/1015 - 0s - loss: 0.6463 - accuracy: 0.6187\n",
      "Epoch 35/100\n",
      "1015/1015 - 0s - loss: 0.6459 - accuracy: 0.6296\n",
      "Epoch 36/100\n",
      "1015/1015 - 0s - loss: 0.6456 - accuracy: 0.6266\n",
      "Epoch 37/100\n",
      "1015/1015 - 0s - loss: 0.6451 - accuracy: 0.6266\n",
      "Epoch 38/100\n",
      "1015/1015 - 0s - loss: 0.6447 - accuracy: 0.6325\n",
      "Epoch 39/100\n",
      "1015/1015 - 0s - loss: 0.6443 - accuracy: 0.6355\n",
      "Epoch 40/100\n",
      "1015/1015 - 0s - loss: 0.6441 - accuracy: 0.6335\n",
      "Epoch 41/100\n",
      "1015/1015 - 0s - loss: 0.6440 - accuracy: 0.6374\n",
      "Epoch 42/100\n",
      "1015/1015 - 0s - loss: 0.6434 - accuracy: 0.6365\n",
      "Epoch 43/100\n",
      "1015/1015 - 0s - loss: 0.6432 - accuracy: 0.6355\n",
      "Epoch 44/100\n",
      "1015/1015 - 0s - loss: 0.6428 - accuracy: 0.6384\n",
      "Epoch 45/100\n",
      "1015/1015 - 0s - loss: 0.6427 - accuracy: 0.6365\n",
      "Epoch 46/100\n",
      "1015/1015 - 0s - loss: 0.6423 - accuracy: 0.6374\n",
      "Epoch 47/100\n",
      "1015/1015 - 0s - loss: 0.6420 - accuracy: 0.6404\n",
      "Epoch 48/100\n",
      "1015/1015 - 0s - loss: 0.6418 - accuracy: 0.6384\n",
      "Epoch 49/100\n",
      "1015/1015 - 0s - loss: 0.6417 - accuracy: 0.6374\n",
      "Epoch 50/100\n",
      "1015/1015 - 0s - loss: 0.6416 - accuracy: 0.6384\n",
      "Epoch 51/100\n",
      "1015/1015 - 0s - loss: 0.6415 - accuracy: 0.6365\n",
      "Epoch 52/100\n",
      "1015/1015 - 0s - loss: 0.6410 - accuracy: 0.6374\n",
      "Epoch 53/100\n",
      "1015/1015 - 0s - loss: 0.6406 - accuracy: 0.6394\n",
      "Epoch 54/100\n",
      "1015/1015 - 0s - loss: 0.6402 - accuracy: 0.6433\n",
      "Epoch 55/100\n",
      "1015/1015 - 0s - loss: 0.6402 - accuracy: 0.6404\n",
      "Epoch 56/100\n",
      "1015/1015 - 0s - loss: 0.6399 - accuracy: 0.6384\n",
      "Epoch 57/100\n",
      "1015/1015 - 0s - loss: 0.6395 - accuracy: 0.6443\n",
      "Epoch 58/100\n",
      "1015/1015 - 0s - loss: 0.6394 - accuracy: 0.6365\n",
      "Epoch 59/100\n",
      "1015/1015 - 0s - loss: 0.6391 - accuracy: 0.6394\n",
      "Epoch 60/100\n",
      "1015/1015 - 0s - loss: 0.6388 - accuracy: 0.6384\n",
      "Epoch 61/100\n",
      "1015/1015 - 0s - loss: 0.6396 - accuracy: 0.6305\n",
      "Epoch 62/100\n",
      "1015/1015 - 0s - loss: 0.6383 - accuracy: 0.6384\n",
      "Epoch 63/100\n",
      "1015/1015 - 0s - loss: 0.6382 - accuracy: 0.6424\n",
      "Epoch 64/100\n",
      "1015/1015 - 0s - loss: 0.6381 - accuracy: 0.6384\n",
      "Epoch 65/100\n",
      "1015/1015 - 0s - loss: 0.6377 - accuracy: 0.6433\n",
      "Epoch 66/100\n",
      "1015/1015 - 0s - loss: 0.6374 - accuracy: 0.6483\n",
      "Epoch 67/100\n",
      "1015/1015 - 0s - loss: 0.6376 - accuracy: 0.6463\n",
      "Epoch 68/100\n",
      "1015/1015 - 0s - loss: 0.6372 - accuracy: 0.6394\n",
      "Epoch 69/100\n",
      "1015/1015 - 0s - loss: 0.6370 - accuracy: 0.6453\n",
      "Epoch 70/100\n",
      "1015/1015 - 0s - loss: 0.6369 - accuracy: 0.6414\n",
      "Epoch 71/100\n",
      "1015/1015 - 0s - loss: 0.6367 - accuracy: 0.6424\n",
      "Epoch 72/100\n",
      "1015/1015 - 0s - loss: 0.6364 - accuracy: 0.6453\n",
      "Epoch 73/100\n",
      "1015/1015 - 0s - loss: 0.6362 - accuracy: 0.6453\n",
      "Epoch 74/100\n",
      "1015/1015 - 0s - loss: 0.6361 - accuracy: 0.6394\n",
      "Epoch 75/100\n",
      "1015/1015 - 0s - loss: 0.6359 - accuracy: 0.6404\n",
      "Epoch 76/100\n",
      "1015/1015 - 0s - loss: 0.6362 - accuracy: 0.6463\n",
      "Epoch 77/100\n",
      "1015/1015 - 0s - loss: 0.6356 - accuracy: 0.6384\n",
      "Epoch 78/100\n",
      "1015/1015 - 0s - loss: 0.6351 - accuracy: 0.6453\n",
      "Epoch 79/100\n",
      "1015/1015 - 0s - loss: 0.6353 - accuracy: 0.6502\n",
      "Epoch 80/100\n",
      "1015/1015 - 0s - loss: 0.6347 - accuracy: 0.6414\n",
      "Epoch 81/100\n",
      "1015/1015 - 0s - loss: 0.6351 - accuracy: 0.6463\n",
      "Epoch 82/100\n",
      "1015/1015 - 0s - loss: 0.6340 - accuracy: 0.6394\n",
      "Epoch 83/100\n",
      "1015/1015 - 0s - loss: 0.6344 - accuracy: 0.6394\n",
      "Epoch 84/100\n",
      "1015/1015 - 0s - loss: 0.6341 - accuracy: 0.6394\n",
      "Epoch 85/100\n",
      "1015/1015 - 0s - loss: 0.6338 - accuracy: 0.6394\n",
      "Epoch 86/100\n",
      "1015/1015 - 0s - loss: 0.6337 - accuracy: 0.6493\n",
      "Epoch 87/100\n",
      "1015/1015 - 0s - loss: 0.6335 - accuracy: 0.6414\n",
      "Epoch 88/100\n",
      "1015/1015 - 0s - loss: 0.6335 - accuracy: 0.6394\n",
      "Epoch 89/100\n",
      "1015/1015 - 0s - loss: 0.6335 - accuracy: 0.6473\n",
      "Epoch 90/100\n",
      "1015/1015 - 0s - loss: 0.6335 - accuracy: 0.6305\n",
      "Epoch 91/100\n",
      "1015/1015 - 0s - loss: 0.6331 - accuracy: 0.6433\n",
      "Epoch 92/100\n",
      "1015/1015 - 0s - loss: 0.6328 - accuracy: 0.6453\n",
      "Epoch 93/100\n",
      "1015/1015 - 0s - loss: 0.6325 - accuracy: 0.6463\n",
      "Epoch 94/100\n",
      "1015/1015 - 0s - loss: 0.6321 - accuracy: 0.6443\n",
      "Epoch 95/100\n",
      "1015/1015 - 0s - loss: 0.6321 - accuracy: 0.6433\n",
      "Epoch 96/100\n",
      "1015/1015 - 0s - loss: 0.6323 - accuracy: 0.6424\n",
      "Epoch 97/100\n",
      "1015/1015 - 0s - loss: 0.6317 - accuracy: 0.6414\n",
      "Epoch 98/100\n",
      "1015/1015 - 0s - loss: 0.6316 - accuracy: 0.6433\n",
      "Epoch 99/100\n",
      "1015/1015 - 0s - loss: 0.6314 - accuracy: 0.6463\n",
      "Epoch 100/100\n",
      "1015/1015 - 0s - loss: 0.6313 - accuracy: 0.6473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ebff433e08>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436/1 - 0s - loss: 0.6667 - accuracy: 0.5780\n",
      "Normal Neural Network - Loss: 0.6878160856185703, Accuracy: 0.5779816508293152\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436/1 - 0s - loss: 0.6513 - accuracy: 0.5734\n",
      "Deep Neural Network - Loss: 0.6758067017301507, Accuracy: 0.5733944773674011\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19687466, 0.8031254 ],\n",
       "       [0.1676274 , 0.83237267],\n",
       "       [0.6729637 , 0.32703632],\n",
       "       [0.16435422, 0.8356458 ],\n",
       "       [0.5253265 , 0.4746735 ],\n",
       "       [0.516746  , 0.48325408],\n",
       "       [0.35923567, 0.6407643 ],\n",
       "       [0.3140553 , 0.68594474],\n",
       "       [0.15062346, 0.84937656],\n",
       "       [0.68458176, 0.31541824],\n",
       "       [0.49131754, 0.5086825 ],\n",
       "       [0.24023634, 0.75976366],\n",
       "       [0.4912488 , 0.5087512 ],\n",
       "       [0.20686412, 0.7931358 ],\n",
       "       [0.6021299 , 0.39787015],\n",
       "       [0.45415148, 0.54584855],\n",
       "       [0.3391969 , 0.66080314],\n",
       "       [0.52758175, 0.47241828],\n",
       "       [0.4986955 , 0.50130445],\n",
       "       [0.40127283, 0.59872717],\n",
       "       [0.610256  , 0.38974392],\n",
       "       [0.34333682, 0.6566631 ],\n",
       "       [0.23270138, 0.76729864],\n",
       "       [0.6962692 , 0.3037308 ],\n",
       "       [0.43885258, 0.5611474 ],\n",
       "       [0.31565106, 0.68434894],\n",
       "       [0.15118226, 0.8488177 ],\n",
       "       [0.5942041 , 0.40579587],\n",
       "       [0.57461804, 0.425382  ],\n",
       "       [0.54107994, 0.45892   ],\n",
       "       [0.2956809 , 0.70431906],\n",
       "       [0.37430292, 0.625697  ],\n",
       "       [0.44308215, 0.55691785],\n",
       "       [0.42550793, 0.57449204],\n",
       "       [0.40946603, 0.590534  ],\n",
       "       [0.45792967, 0.5420703 ],\n",
       "       [0.5316245 , 0.46837556],\n",
       "       [0.2021392 , 0.79786086],\n",
       "       [0.5850007 , 0.41499928],\n",
       "       [0.45340276, 0.5465973 ],\n",
       "       [0.18222594, 0.81777406],\n",
       "       [0.7779429 , 0.22205716],\n",
       "       [0.3311872 , 0.6688128 ],\n",
       "       [0.46547598, 0.53452396],\n",
       "       [0.36134195, 0.638658  ],\n",
       "       [0.44408932, 0.5559106 ],\n",
       "       [0.58441013, 0.41558984],\n",
       "       [0.44628793, 0.55371207],\n",
       "       [0.2490799 , 0.75092006],\n",
       "       [0.521446  , 0.47855404],\n",
       "       [0.42341405, 0.5765859 ],\n",
       "       [0.4735195 , 0.52648044],\n",
       "       [0.5225816 , 0.47741845],\n",
       "       [0.35654035, 0.6434597 ],\n",
       "       [0.6370841 , 0.36291593],\n",
       "       [0.14238991, 0.85761005],\n",
       "       [0.30292344, 0.6970765 ],\n",
       "       [0.21761316, 0.78238684],\n",
       "       [0.28901014, 0.71098983],\n",
       "       [0.59053254, 0.40946752],\n",
       "       [0.2988712 , 0.7011288 ],\n",
       "       [0.3025234 , 0.69747657],\n",
       "       [0.40800083, 0.5919991 ],\n",
       "       [0.16571741, 0.83428264],\n",
       "       [0.518288  , 0.48171195],\n",
       "       [0.4247262 , 0.57527375],\n",
       "       [0.41033664, 0.58966327],\n",
       "       [0.4665477 , 0.53345233],\n",
       "       [0.16947989, 0.8305201 ],\n",
       "       [0.06672207, 0.9332779 ],\n",
       "       [0.40739644, 0.59260356],\n",
       "       [0.34839666, 0.65160334],\n",
       "       [0.28979665, 0.7102033 ],\n",
       "       [0.45190147, 0.5480985 ],\n",
       "       [0.4650268 , 0.5349732 ],\n",
       "       [0.39695644, 0.60304356],\n",
       "       [0.53651434, 0.4634856 ],\n",
       "       [0.23731862, 0.7626814 ],\n",
       "       [0.26251382, 0.7374862 ],\n",
       "       [0.45476237, 0.54523766],\n",
       "       [0.35908118, 0.6409188 ],\n",
       "       [0.6208608 , 0.37913916],\n",
       "       [0.31378287, 0.68621707],\n",
       "       [0.61872846, 0.38127148],\n",
       "       [0.42504033, 0.57495964],\n",
       "       [0.83186364, 0.16813642],\n",
       "       [0.42788702, 0.572113  ],\n",
       "       [0.27776444, 0.72223556],\n",
       "       [0.35678262, 0.6432173 ],\n",
       "       [0.20290726, 0.7970928 ],\n",
       "       [0.42245296, 0.577547  ],\n",
       "       [0.36340445, 0.6365955 ],\n",
       "       [0.60765374, 0.3923462 ],\n",
       "       [0.62366915, 0.37633085],\n",
       "       [0.37204188, 0.62795806],\n",
       "       [0.19333483, 0.80666524],\n",
       "       [0.218873  , 0.78112704],\n",
       "       [0.43857497, 0.561425  ],\n",
       "       [0.49294034, 0.50705963],\n",
       "       [0.4247551 , 0.5752449 ],\n",
       "       [0.3917479 , 0.6082521 ],\n",
       "       [0.6623014 , 0.33769852],\n",
       "       [0.52779305, 0.47220698],\n",
       "       [0.7090141 , 0.2909858 ],\n",
       "       [0.35606742, 0.6439326 ],\n",
       "       [0.40408754, 0.59591246],\n",
       "       [0.58757025, 0.41242975],\n",
       "       [0.08457966, 0.91542035],\n",
       "       [0.8533278 , 0.14667219],\n",
       "       [0.5202083 , 0.4797916 ],\n",
       "       [0.3472142 , 0.65278584],\n",
       "       [0.44552356, 0.5544764 ],\n",
       "       [0.27280533, 0.72719467],\n",
       "       [0.24370895, 0.75629103],\n",
       "       [0.45733985, 0.5426602 ],\n",
       "       [0.20714793, 0.7928521 ],\n",
       "       [0.15756065, 0.84243935],\n",
       "       [0.4414039 , 0.5585961 ],\n",
       "       [0.19658886, 0.8034111 ],\n",
       "       [0.29294777, 0.7070522 ],\n",
       "       [0.3637702 , 0.6362298 ],\n",
       "       [0.48970097, 0.51029897],\n",
       "       [0.3278998 , 0.6721002 ],\n",
       "       [0.3307447 , 0.66925526],\n",
       "       [0.34691918, 0.6530808 ],\n",
       "       [0.5276632 , 0.47233683],\n",
       "       [0.36145395, 0.63854605],\n",
       "       [0.45138896, 0.54861104],\n",
       "       [0.38423598, 0.61576396],\n",
       "       [0.45037135, 0.5496287 ],\n",
       "       [0.65269566, 0.3473044 ],\n",
       "       [0.6782955 , 0.32170445],\n",
       "       [0.55348355, 0.44651645],\n",
       "       [0.39694965, 0.60305035],\n",
       "       [0.26323915, 0.73676085],\n",
       "       [0.49597454, 0.5040254 ],\n",
       "       [0.28207594, 0.717924  ],\n",
       "       [0.22325654, 0.77674353],\n",
       "       [0.3122857 , 0.68771434],\n",
       "       [0.36300892, 0.636991  ],\n",
       "       [0.42167595, 0.5783241 ],\n",
       "       [0.30281383, 0.6971862 ],\n",
       "       [0.3544461 , 0.6455538 ],\n",
       "       [0.5891869 , 0.4108131 ],\n",
       "       [0.2586286 , 0.74137133],\n",
       "       [0.2763533 , 0.7236467 ],\n",
       "       [0.37221438, 0.6277857 ],\n",
       "       [0.46580988, 0.53419006],\n",
       "       [0.37125543, 0.62874454],\n",
       "       [0.4266036 , 0.57339644],\n",
       "       [0.61190367, 0.3880963 ],\n",
       "       [0.6478267 , 0.3521734 ],\n",
       "       [0.40067852, 0.5993214 ],\n",
       "       [0.35378408, 0.6462159 ],\n",
       "       [0.66196716, 0.3380328 ],\n",
       "       [0.1430527 , 0.8569473 ],\n",
       "       [0.3518544 , 0.6481456 ],\n",
       "       [0.37534377, 0.62465626],\n",
       "       [0.42205077, 0.5779493 ],\n",
       "       [0.76039094, 0.23960908],\n",
       "       [0.76245445, 0.23754555],\n",
       "       [0.55460215, 0.44539788],\n",
       "       [0.74040526, 0.25959474],\n",
       "       [0.33619732, 0.6638026 ],\n",
       "       [0.3630697 , 0.6369303 ],\n",
       "       [0.41736466, 0.58263534],\n",
       "       [0.29726517, 0.7027348 ],\n",
       "       [0.3862854 , 0.61371464],\n",
       "       [0.38808206, 0.6119179 ],\n",
       "       [0.52781534, 0.47218466],\n",
       "       [0.41087312, 0.5891269 ],\n",
       "       [0.63467443, 0.36532557],\n",
       "       [0.46022913, 0.5397709 ],\n",
       "       [0.48017344, 0.5198266 ],\n",
       "       [0.49805558, 0.50194436],\n",
       "       [0.38239   , 0.61761   ],\n",
       "       [0.39071262, 0.6092874 ],\n",
       "       [0.26860267, 0.7313973 ],\n",
       "       [0.40738302, 0.59261703],\n",
       "       [0.36756077, 0.63243926],\n",
       "       [0.5799022 , 0.42009777],\n",
       "       [0.59791476, 0.40208524],\n",
       "       [0.4655856 , 0.53441447],\n",
       "       [0.2916382 , 0.7083618 ],\n",
       "       [0.69770455, 0.30229542],\n",
       "       [0.6421572 , 0.3578428 ],\n",
       "       [0.3954069 , 0.6045931 ],\n",
       "       [0.32174596, 0.678254  ],\n",
       "       [0.45869383, 0.5413062 ],\n",
       "       [0.41882488, 0.5811751 ],\n",
       "       [0.4274417 , 0.5725583 ],\n",
       "       [0.38517308, 0.61482686],\n",
       "       [0.39847314, 0.60152686],\n",
       "       [0.4665668 , 0.5334332 ],\n",
       "       [0.33231083, 0.66768914],\n",
       "       [0.19461542, 0.80538464],\n",
       "       [0.47864145, 0.5213585 ],\n",
       "       [0.29089734, 0.7091027 ],\n",
       "       [0.5420493 , 0.4579507 ],\n",
       "       [0.35064116, 0.64935887],\n",
       "       [0.64259607, 0.3574039 ],\n",
       "       [0.41165084, 0.58834916],\n",
       "       [0.54841226, 0.45158774],\n",
       "       [0.3847226 , 0.6152774 ],\n",
       "       [0.5014845 , 0.49851555],\n",
       "       [0.58730656, 0.41269344],\n",
       "       [0.46643767, 0.5335623 ],\n",
       "       [0.51235795, 0.48764205],\n",
       "       [0.43322113, 0.5667789 ],\n",
       "       [0.21405259, 0.7859474 ],\n",
       "       [0.3038313 , 0.6961687 ],\n",
       "       [0.37941366, 0.6205863 ],\n",
       "       [0.6333859 , 0.36661407],\n",
       "       [0.59862643, 0.4013736 ],\n",
       "       [0.4072504 , 0.5927496 ],\n",
       "       [0.32054585, 0.67945415],\n",
       "       [0.2844434 , 0.71555656],\n",
       "       [0.45996353, 0.54003644],\n",
       "       [0.4931827 , 0.5068172 ],\n",
       "       [0.42963722, 0.57036275],\n",
       "       [0.26702005, 0.73297995],\n",
       "       [0.54030186, 0.4596981 ],\n",
       "       [0.5278283 , 0.47217172],\n",
       "       [0.38560075, 0.6143992 ],\n",
       "       [0.52570194, 0.4742981 ],\n",
       "       [0.34166533, 0.6583347 ],\n",
       "       [0.19480729, 0.80519277],\n",
       "       [0.3922106 , 0.60778934],\n",
       "       [0.5362438 , 0.46375623],\n",
       "       [0.28452182, 0.7154782 ],\n",
       "       [0.65756345, 0.34243652],\n",
       "       [0.11317486, 0.8868252 ],\n",
       "       [0.1778152 , 0.82218486],\n",
       "       [0.3276539 , 0.67234606],\n",
       "       [0.47821823, 0.52178174],\n",
       "       [0.27922952, 0.7207704 ],\n",
       "       [0.42988253, 0.57011753],\n",
       "       [0.45977908, 0.5402209 ],\n",
       "       [0.40060106, 0.599399  ],\n",
       "       [0.31605878, 0.6839412 ],\n",
       "       [0.5037467 , 0.4962534 ],\n",
       "       [0.60797894, 0.39202103],\n",
       "       [0.55433625, 0.44566366],\n",
       "       [0.38214985, 0.6178502 ],\n",
       "       [0.43864614, 0.5613538 ],\n",
       "       [0.6302966 , 0.36970338],\n",
       "       [0.18377829, 0.8162217 ],\n",
       "       [0.39865556, 0.60134447],\n",
       "       [0.42176956, 0.5782304 ],\n",
       "       [0.654999  , 0.34500104],\n",
       "       [0.44563335, 0.55436665],\n",
       "       [0.3288044 , 0.6711956 ],\n",
       "       [0.56933457, 0.4306654 ],\n",
       "       [0.3435321 , 0.6564679 ],\n",
       "       [0.22417335, 0.7758267 ],\n",
       "       [0.40352234, 0.5964776 ],\n",
       "       [0.38194004, 0.61805993],\n",
       "       [0.52592564, 0.47407436],\n",
       "       [0.42790776, 0.57209224],\n",
       "       [0.5029938 , 0.49700612],\n",
       "       [0.5664926 , 0.43350744],\n",
       "       [0.36593154, 0.6340684 ],\n",
       "       [0.38024774, 0.6197522 ],\n",
       "       [0.4945609 , 0.5054391 ],\n",
       "       [0.5094982 , 0.49050182],\n",
       "       [0.48624405, 0.513756  ],\n",
       "       [0.29550543, 0.7044946 ],\n",
       "       [0.29542428, 0.70457566],\n",
       "       [0.49597648, 0.50402355],\n",
       "       [0.2786528 , 0.7213472 ],\n",
       "       [0.5721082 , 0.42789182],\n",
       "       [0.36019343, 0.63980657],\n",
       "       [0.43031687, 0.56968313],\n",
       "       [0.71631867, 0.28368127],\n",
       "       [0.39504075, 0.6049592 ],\n",
       "       [0.7072178 , 0.29278216],\n",
       "       [0.33549315, 0.6645069 ],\n",
       "       [0.48571515, 0.51428485],\n",
       "       [0.31946388, 0.6805361 ],\n",
       "       [0.5337882 , 0.46621183],\n",
       "       [0.8051974 , 0.19480269],\n",
       "       [0.4339395 , 0.5660605 ],\n",
       "       [0.50335443, 0.49664563],\n",
       "       [0.36263737, 0.63736266],\n",
       "       [0.5172129 , 0.48278707],\n",
       "       [0.2904495 , 0.70955056],\n",
       "       [0.49735075, 0.50264925],\n",
       "       [0.3152012 , 0.68479884],\n",
       "       [0.48836595, 0.511634  ],\n",
       "       [0.39713377, 0.6028662 ],\n",
       "       [0.5937005 , 0.4062995 ],\n",
       "       [0.4679025 , 0.53209746],\n",
       "       [0.16057359, 0.83942646],\n",
       "       [0.26144966, 0.7385503 ],\n",
       "       [0.48017448, 0.5198255 ],\n",
       "       [0.42379004, 0.57620996],\n",
       "       [0.34774712, 0.6522529 ],\n",
       "       [0.38528484, 0.6147151 ],\n",
       "       [0.57384783, 0.42615208],\n",
       "       [0.3222892 , 0.6777108 ],\n",
       "       [0.44188476, 0.5581153 ],\n",
       "       [0.42031735, 0.5796826 ],\n",
       "       [0.86015594, 0.13984405],\n",
       "       [0.43734205, 0.5626579 ],\n",
       "       [0.3950031 , 0.60499686],\n",
       "       [0.48005742, 0.5199426 ],\n",
       "       [0.45682353, 0.5431764 ],\n",
       "       [0.41389793, 0.586102  ],\n",
       "       [0.42331412, 0.5766859 ],\n",
       "       [0.5110561 , 0.48894387],\n",
       "       [0.65254545, 0.34745455],\n",
       "       [0.41900265, 0.5809974 ],\n",
       "       [0.5521985 , 0.4478014 ],\n",
       "       [0.28104123, 0.7189587 ],\n",
       "       [0.51985806, 0.48014185],\n",
       "       [0.34670419, 0.65329576],\n",
       "       [0.30713817, 0.69286186],\n",
       "       [0.19360138, 0.80639863],\n",
       "       [0.41751534, 0.58248466],\n",
       "       [0.56350696, 0.43649304],\n",
       "       [0.18656753, 0.8134325 ],\n",
       "       [0.55658245, 0.4434176 ],\n",
       "       [0.49967548, 0.5003246 ],\n",
       "       [0.467212  , 0.53278804],\n",
       "       [0.38196146, 0.6180385 ],\n",
       "       [0.7148517 , 0.28514823],\n",
       "       [0.4994718 , 0.50052816],\n",
       "       [0.33853906, 0.6614609 ],\n",
       "       [0.32770872, 0.6722913 ],\n",
       "       [0.28094015, 0.7190598 ],\n",
       "       [0.39902323, 0.60097677],\n",
       "       [0.38253143, 0.61746854],\n",
       "       [0.53910065, 0.46089938],\n",
       "       [0.34829554, 0.65170443],\n",
       "       [0.25922096, 0.74077904],\n",
       "       [0.31547546, 0.68452454],\n",
       "       [0.5093636 , 0.4906364 ],\n",
       "       [0.42944303, 0.570557  ],\n",
       "       [0.60735744, 0.39264256],\n",
       "       [0.15146999, 0.84853   ],\n",
       "       [0.28489518, 0.7151048 ],\n",
       "       [0.27281916, 0.7271808 ],\n",
       "       [0.511044  , 0.48895594],\n",
       "       [0.32942325, 0.67057675],\n",
       "       [0.41958582, 0.5804141 ],\n",
       "       [0.63048404, 0.36951602],\n",
       "       [0.5263938 , 0.47360626],\n",
       "       [0.42732057, 0.57267946],\n",
       "       [0.50995964, 0.49004033],\n",
       "       [0.2548204 , 0.7451796 ],\n",
       "       [0.22836535, 0.7716347 ],\n",
       "       [0.43943742, 0.56056255],\n",
       "       [0.8622946 , 0.13770537],\n",
       "       [0.37210625, 0.62789375],\n",
       "       [0.6440395 , 0.3559605 ],\n",
       "       [0.3171772 , 0.68282276],\n",
       "       [0.5243208 , 0.47567925],\n",
       "       [0.41845223, 0.58154774],\n",
       "       [0.3351934 , 0.6648066 ],\n",
       "       [0.3558385 , 0.6441615 ],\n",
       "       [0.36600313, 0.63399684],\n",
       "       [0.74615645, 0.2538435 ],\n",
       "       [0.33226085, 0.66773915],\n",
       "       [0.3636511 , 0.63634896],\n",
       "       [0.50786364, 0.49213642],\n",
       "       [0.37068507, 0.6293149 ],\n",
       "       [0.31493416, 0.68506587],\n",
       "       [0.41884956, 0.5811504 ],\n",
       "       [0.5454844 , 0.45451558],\n",
       "       [0.49544942, 0.5045506 ],\n",
       "       [0.35826963, 0.6417303 ],\n",
       "       [0.38958997, 0.61041   ],\n",
       "       [0.474708  , 0.525292  ],\n",
       "       [0.40182647, 0.5981735 ],\n",
       "       [0.33951128, 0.6604887 ],\n",
       "       [0.316168  , 0.68383193],\n",
       "       [0.43774003, 0.56226   ],\n",
       "       [0.42577782, 0.57422215],\n",
       "       [0.2917867 , 0.7082132 ],\n",
       "       [0.42644215, 0.5735578 ],\n",
       "       [0.46235904, 0.5376409 ],\n",
       "       [0.4006362 , 0.5993638 ],\n",
       "       [0.36973548, 0.6302645 ],\n",
       "       [0.874405  , 0.12559496],\n",
       "       [0.40076667, 0.5992333 ],\n",
       "       [0.44912395, 0.5508761 ],\n",
       "       [0.43587732, 0.5641227 ],\n",
       "       [0.6927514 , 0.30724856],\n",
       "       [0.48240936, 0.51759064],\n",
       "       [0.60348856, 0.3965114 ],\n",
       "       [0.57050085, 0.4294991 ],\n",
       "       [0.587124  , 0.41287598],\n",
       "       [0.4697348 , 0.5302652 ],\n",
       "       [0.32526323, 0.6747367 ],\n",
       "       [0.3120959 , 0.68790406],\n",
       "       [0.30671886, 0.6932811 ],\n",
       "       [0.4178508 , 0.5821492 ],\n",
       "       [0.28382275, 0.7161772 ],\n",
       "       [0.55811924, 0.44188073],\n",
       "       [0.31362674, 0.6863732 ],\n",
       "       [0.4776    , 0.5224    ],\n",
       "       [0.5827438 , 0.4172562 ],\n",
       "       [0.45789236, 0.5421076 ],\n",
       "       [0.510458  , 0.48954207],\n",
       "       [0.48968902, 0.51031095],\n",
       "       [0.36824977, 0.6317502 ],\n",
       "       [0.5190182 , 0.48098192],\n",
       "       [0.69356346, 0.30643654],\n",
       "       [0.29518133, 0.7048186 ],\n",
       "       [0.35475233, 0.64524764],\n",
       "       [0.5404226 , 0.45957732],\n",
       "       [0.28237072, 0.71762925],\n",
       "       [0.5186728 , 0.4813272 ],\n",
       "       [0.3671737 , 0.6328263 ],\n",
       "       [0.6150271 , 0.3849728 ],\n",
       "       [0.18076703, 0.819233  ],\n",
       "       [0.4914719 , 0.5085281 ],\n",
       "       [0.23287262, 0.7671274 ],\n",
       "       [0.5736602 , 0.4263398 ],\n",
       "       [0.4708807 , 0.52911925],\n",
       "       [0.30400717, 0.6959928 ],\n",
       "       [0.3559503 , 0.64404976],\n",
       "       [0.43445587, 0.56554407],\n",
       "       [0.6125068 , 0.38749316],\n",
       "       [0.6770881 , 0.3229119 ],\n",
       "       [0.2008614 , 0.7991386 ],\n",
       "       [0.12996854, 0.8700314 ],\n",
       "       [0.39881918, 0.6011808 ],\n",
       "       [0.49519765, 0.5048023 ],\n",
       "       [0.22036655, 0.7796335 ],\n",
       "       [0.49064746, 0.5093525 ],\n",
       "       [0.40490496, 0.59509504],\n",
       "       [0.384837  , 0.615163  ],\n",
       "       [0.67931527, 0.32068473],\n",
       "       [0.36046928, 0.63953066],\n",
       "       [0.39425   , 0.60574996]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        red\n",
       "1       blue\n",
       "2        red\n",
       "3       blue\n",
       "4        red\n",
       "        ... \n",
       "1472     red\n",
       "1473     red\n",
       "1474    blue\n",
       "1475    blue\n",
       "1476     red\n",
       "Name: winner, Length: 1451, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223     red\n",
       "537      red\n",
       "1111    blue\n",
       "597     blue\n",
       "38       red\n",
       "Name: winner, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[-0.9264837  -0.62285573  1.49120559 -0.84085188 -0.83531737 -1.07800247\n",
      " -0.6495086   0.15864884 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573  0.9921794  -0.84085188 -0.57019944  0.44027575\n",
      "  1.08536305 -1.31500384 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[ 1.18317632  0.34528909 -0.25538609  0.31154437  0.22515434 -1.07800247\n",
      " -0.6495086  -0.33256872  0.51628197  0.20700552], Predicted=blue\n",
      "X=[ 0.12834631 -0.62285573  1.2416925  -0.26465376 -0.57019944 -1.07800247\n",
      " -0.6495086  -1.06939506 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229 -0.61037263 -0.83531737 -1.07800247\n",
      " -0.6495086   0.64986639 -1.16868973 -0.84453332], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.50295158  0.31154437  0.22515434 -1.07800247\n",
      " -0.6495086  -1.31500384 -0.04537526  0.20700552], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573  1.99023179 -0.26465376  0.22515434  1.95855398\n",
      " -0.6495086   0.40425762 -0.27003816  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.49120559 -0.61037263  0.22515434 -0.57190973\n",
      " -0.6495086  -0.82378628  1.0779392   0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.2436401  -1.99324813 -1.16671478 -0.06581699\n",
      "  1.08536305 -1.31500384 -1.39335262 -1.17313921], Predicted=red\n",
      "X=[ 1.71059132  3.24972355 -1.00392538  0.88774249  0.68911071  1.95855398\n",
      "  0.21792723  0.89547517  0.85327631  0.66705377], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  0.88774249  0.68911071 -1.07800247\n",
      " -0.6495086  -0.33256872  0.29161908  0.20700552], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573 -0.25538609 -0.03417451 -0.23880203  1.45246124\n",
      "  1.95279888 -0.82378628 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -1.50295158 -0.61037263 -0.57019944  0.44027575\n",
      "  1.08536305  0.15864884 -0.27003816 -0.58164861], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.00587299  0.54202361  0.22515434  1.45246124\n",
      "  3.68767053 -0.82378628 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -1.50295158 -0.84085188 -0.83531737 -0.06581699\n",
      "  0.21792723  1.38669273 -0.83169539 -0.84453332], Predicted=blue\n",
      "X=[ 2.23800633  0.34528909  1.2416925   0.54202361  0.68911071  1.95855398\n",
      " -0.6495086   0.64986639  0.51628197  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -0.26465376 -0.57019944 -0.57190973\n",
      "  0.21792723 -1.31500384 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.75246468  0.54202361  0.22515434 -1.07800247\n",
      " -0.6495086   0.40425762 -0.04537526  0.20700552], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.75441229 -0.03417451  0.22515434 -1.07800247\n",
      " -0.6495086  -0.08695994 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.7426663   0.54202361  0.22515434 -1.07800247\n",
      " -0.6495086  -1.31500384  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573 -0.25538609  1.11822174  1.28562604 -1.07800247\n",
      " -0.6495086  -0.08695994  0.85327631  1.25854437], Predicted=blue\n",
      "X=[-0.39906869  0.34528909  0.7426663  -0.26465376  0.22515434 -0.57190973\n",
      "  0.21792723 -1.06939506  0.51628197  0.20700552], Predicted=red\n",
      "X=[ 1.71059132 -0.62285573  1.49120559  0.88774249  1.28562604 -0.57190973\n",
      " -0.6495086  -1.31500384 -0.04537526  1.25854437], Predicted=red\n",
      "X=[ 1.18317632  2.28157873 -0.00587299  0.31154437 -0.57019944 -0.06581699\n",
      "  1.08536305  0.15864884  0.51628197 -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.26465376 -0.57019944 -1.07800247\n",
      " -0.6495086   0.64986639 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909  2.23974489  1.11822174  1.28562604  1.45246124\n",
      "  0.21792723  0.40425762  1.0779392   1.25854437], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.00392538  0.54202361  0.68911071  0.44027575\n",
      "  1.95279888  0.64986639  1.41493354  0.66705377], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -2.00197778 -1.18657076 -1.16671478 -0.57190973\n",
      " -0.6495086   1.14108395 -0.27003816 -0.58164861], Predicted=blue\n",
      "X=[ 1.18317632  1.31343391  0.4931532   1.46394061  1.28562604 -0.06581699\n",
      " -0.6495086   1.38669273  1.0779392   1.25854437], Predicted=blue\n",
      "X=[ 2.23800633  1.31343391 -0.75441229 -0.03417451 -0.57019944  0.9463685\n",
      "  2.8202347  -1.8062214   0.29161908 -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.25343848 -1.99324813 -1.4318327  -1.07800247\n",
      " -0.6495086  -1.56061262 -1.73034696 -1.43602393], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532   0.54202361  0.68911071 -1.07800247\n",
      " -0.6495086  -0.82378628  1.0779392   0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.84085188 -0.57019944 -1.07800247\n",
      " -0.6495086  -0.82378628 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -1.75246468 -0.03417451 -0.23880203 -0.06581699\n",
      "  0.21792723 -1.06939506  0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.9921794   1.11822174  0.22515434 -0.06581699\n",
      " -0.6495086   0.64986639 -0.27003816  0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.75441229  0.31154437  0.22515434 -0.57190973\n",
      " -0.6495086  -0.33256872  0.51628197  0.20700552], Predicted=red\n",
      "X=[ 0.65576131  0.34528909 -0.00587299  0.31154437 -0.23880203 -0.57190973\n",
      "  0.21792723 -0.33256872 -0.27003816 -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.7426663  -1.41705001 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.08695994 -1.39335262 -1.17313921], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.50295158 -1.18657076 -1.16671478 -0.57190973\n",
      " -0.6495086   0.15864884 -1.73034696 -1.17313921], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.2436401   1.46394061  0.22515434 -1.07800247\n",
      " -0.6495086  -0.33256872 -0.04537526  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401  -0.26465376 -0.57019944 -0.57190973\n",
      " -0.6495086  -2.29743896 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[ 1.71059132  2.28157873 -0.50489919 -0.26465376 -0.23880203  0.44027575\n",
      "  1.95279888  0.15864884  0.29161908  0.20700552], Predicted=blue\n",
      "X=[ 1.18317632  3.24972355  0.9921794  -1.18657076 -0.57019944  0.44027575\n",
      " -0.6495086  -0.33256872 -0.83169539 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401   0.31154437  0.22515434 -0.06581699\n",
      " -0.6495086  -0.08695994  1.0779392   0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532  -0.61037263 -0.23880203 -1.07800247\n",
      " -0.6495086   0.15864884 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.26465376 -0.23880203 -1.07800247\n",
      " -0.6495086  -1.06939506  0.85327631 -0.58164861], Predicted=red\n",
      "X=[ 2.76542133 -0.62285573 -0.00587299 -0.61037263 -0.23880203  0.9463685\n",
      " -0.6495086   0.15864884  0.29161908 -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  0.88774249 -0.23880203 -0.57190973\n",
      " -0.6495086  -0.5781775   0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532  -1.18657076 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.33256872 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[ 0.65576131  2.28157873 -1.00392538 -1.18657076 -0.83531737  0.44027575\n",
      "  0.21792723 -0.5781775  -1.39335262 -0.84453332], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  0.31154437  0.22515434  0.44027575\n",
      " -0.6495086  -0.82378628 -0.04537526  0.20700552], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.25538609  1.11822174 -0.23880203 -0.06581699\n",
      "  1.08536305  0.15864884  0.29161908  0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.50489919  0.31154437  0.22515434 -1.07800247\n",
      " -0.6495086  -0.5781775   0.51628197  0.20700552], Predicted=blue\n",
      "X=[0.65576131 2.28157873 0.4931532  1.11822174 1.28562604 0.9463685\n",
      " 0.21792723 0.40425762 1.0779392  1.25854437], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -0.75441229 -0.03417451 -0.57019944 -0.06581699\n",
      " -0.6495086   0.89547517 -0.6070325  -0.84453332], Predicted=blue\n",
      "X=[ 0.12834631  1.31343391 -1.50295158  1.11822174  0.22515434  0.9463685\n",
      "  0.21792723 -2.54304774  0.51628197 -0.25304272], Predicted=red\n",
      "X=[ 1.18317632  0.34528909  0.4931532  -0.84085188 -0.83531737  0.44027575\n",
      "  1.95279888 -1.56061262 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.75441229  0.31154437 -0.57019944  0.9463685\n",
      "  2.8202347   0.40425762  0.85327631  0.20700552], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -0.00587299  1.46394061  1.28562604 -0.06581699\n",
      " -0.6495086   3.10595419  1.41493354  1.25854437], Predicted=red\n",
      "X=[-0.39906869  0.34528909  1.2416925   2.04013874  2.94261308 -1.07800247\n",
      " -0.6495086  -0.08695994  1.41493354  2.90157382], Predicted=blue\n",
      "X=[ 0.65576131  2.28157873  0.9921794  -0.03417451  0.22515434  1.45246124\n",
      "  3.68767053 -0.5781775   1.41493354  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.9921794  -0.26465376 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.5781775  -0.83169539 -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.00587299 -0.03417451  0.22515434 -0.57190973\n",
      " -0.6495086   0.15864884  1.41493354  0.20700552], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.9921794  -0.61037263 -0.57019944  0.9463685\n",
      "  2.8202347  -0.33256872 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[0.65576131 2.28157873 0.9921794  0.88774249 0.68911071 0.9463685\n",
      " 0.21792723 1.63230151 0.85327631 0.66705377], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573 -0.50489919 -0.03417451  0.22515434 -0.57190973\n",
      " -0.6495086   1.14108395  0.29161908  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.00392538  0.54202361 -0.23880203 -0.06581699\n",
      " -0.6495086  -1.06939506 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.00392538 -1.41705001 -0.83531737 -0.57190973\n",
      " -0.6495086  -0.33256872 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.25538609 -0.03417451 -0.83531737 -0.06581699\n",
      "  0.21792723 -2.05183018 -1.16868973 -1.17313921], Predicted=red\n",
      "X=[2.23800633 0.34528909 3.73682347 0.31154437 0.68911071 2.46464672\n",
      " 2.8202347  1.63230151 0.85327631 0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532   0.31154437 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.08695994 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[ 1.71059132 -0.62285573 -0.25538609 -1.76276888 -1.16671478  0.9463685\n",
      "  2.8202347   0.15864884 -1.73034696 -1.17313921], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  1.49120559  0.88774249 -0.23880203  0.44027575\n",
      " -0.6495086  -0.08695994 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573 -0.50489919 -0.26465376  0.22515434 -1.07800247\n",
      " -0.6495086   1.38669273  0.85327631  0.20700552], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -1.25343848 -0.03417451  0.22515434 -0.57190973\n",
      "  0.21792723 -1.31500384  1.41493354  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.9921794   1.46394061  0.68911071 -1.07800247\n",
      " -0.6495086   1.38669273  0.85327631  0.66705377], Predicted=red\n",
      "X=[ 1.18317632  0.34528909  0.7426663  -0.84085188  0.22515434  1.95855398\n",
      " -0.6495086   0.40425762  1.0779392   0.20700552], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -1.18657076 -1.16671478 -1.07800247\n",
      " -0.6495086  -1.31500384 -1.39335262 -1.17313921], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.7426663  -1.18657076 -0.83531737 -1.07800247\n",
      " -0.6495086   0.64986639 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -0.84085188 -0.57019944  1.95855398\n",
      " -0.6495086  -0.08695994 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.50295158  1.46394061  0.22515434  1.45246124\n",
      " -0.6495086  -0.5781775   0.85327631  0.20700552], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.50489919 -0.84085188 -0.57019944  0.9463685\n",
      " -0.6495086   0.89547517 -0.6070325  -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  1.99023179 -0.03417451  0.22515434 -0.06581699\n",
      " -0.6495086  -0.08695994 -0.27003816  0.20700552], Predicted=red\n",
      "X=[ 1.18317632  2.28157873 -0.25538609  0.54202361  0.22515434  0.9463685\n",
      "  0.21792723  0.89547517  0.85327631  0.20700552], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  1.2416925   1.11822174  1.28562604 -1.07800247\n",
      " -0.6495086   1.63230151  0.29161908  1.25854437], Predicted=red\n",
      "X=[ 2.23800633  1.31343391 -2.00197778 -1.18657076 -1.16671478  1.95855398\n",
      " -0.6495086   0.40425762 -1.16868973 -1.17313921], Predicted=blue\n",
      "X=[ 1.18317632  1.31343391  0.4931532   0.88774249  1.28562604  0.9463685\n",
      "  0.21792723  0.40425762 -0.04537526  1.25854437], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573  0.4931532  -0.84085188 -0.57019944  1.45246124\n",
      "  0.21792723 -0.33256872 -1.16868973 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.9921794  -0.61037263 -0.23880203 -0.57190973\n",
      " -0.6495086  -0.33256872  0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -2.00197778 -0.84085188 -1.16671478  1.95855398\n",
      "  2.8202347  -1.56061262 -0.27003816 -1.17313921], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.25343848 -0.26465376 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.82378628 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[-0.39906869  0.34528909  1.2416925   0.54202361  0.22515434 -0.57190973\n",
      "  0.21792723  1.14108395  0.85327631  0.20700552], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -1.75246468  0.31154437 -0.57019944  0.9463685\n",
      " -0.6495086   0.40425762 -0.83169539 -0.58164861], Predicted=blue\n",
      "X=[ 0.65576131  0.34528909  0.7426663   1.11822174  0.68911071 -1.07800247\n",
      " -0.6495086   0.89547517  0.29161908  0.66705377], Predicted=blue\n",
      "X=[-0.39906869  0.34528909  0.4931532  -0.84085188 -0.83531737 -1.07800247\n",
      " -0.6495086   0.15864884 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[ 1.18317632  1.31343391  1.74071869 -0.84085188 -0.57019944  0.9463685\n",
      " -0.6495086  -0.33256872 -1.16868973 -0.58164861], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573  1.74071869 -0.61037263 -0.23880203  1.45246124\n",
      " -0.6495086   0.40425762 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.50489919 -0.03417451  0.22515434 -0.06581699\n",
      "  1.08536305 -0.5781775   0.85327631  0.20700552], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573  0.2436401  -1.18657076 -1.16671478 -0.06581699\n",
      " -0.6495086   1.63230151 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573 -0.00587299 -0.03417451 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.5781775  -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.00587299  0.54202361  0.68911071 -0.57190973\n",
      " -0.6495086   0.89547517  1.0779392   0.66705377], Predicted=red\n",
      "X=[ 0.65576131  2.28157873 -1.00392538 -0.03417451 -0.23880203 -0.06581699\n",
      "  0.21792723  0.40425762  0.29161908 -0.25304272], Predicted=blue\n",
      "X=[ 0.12834631  0.34528909 -1.00392538 -0.03417451 -0.23880203 -0.06581699\n",
      "  1.08536305 -0.5781775  -0.04537526 -0.25304272], Predicted=blue\n",
      "X=[ 0.65576131  0.34528909 -0.50489919 -1.18657076 -1.16671478  0.9463685\n",
      " -0.6495086   1.38669273 -1.73034696 -1.17313921], Predicted=blue\n",
      "X=[ 0.12834631 -0.62285573 -0.50489919  1.46394061  1.28562604  0.44027575\n",
      " -0.6495086   0.40425762 -0.04537526  1.25854437], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -0.26465376 -0.23880203 -0.06581699\n",
      " -0.6495086  -1.31500384  0.51628197 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.50295158 -1.76276888 -1.4318327  -0.57190973\n",
      " -0.6495086   1.63230151 -1.95500986 -1.43602393], Predicted=blue\n",
      "X=[ 0.12834631  0.34528909 -0.00587299 -0.61037263 -0.23880203  1.95855398\n",
      "  4.55510636  0.40425762  0.85327631  0.20700552], Predicted=red\n",
      "X=[ 3.29283633  1.31343391 -0.00587299  1.11822174  0.68911071  0.44027575\n",
      " -0.6495086   1.87791029  0.51628197  0.66705377], Predicted=blue\n",
      "X=[-0.39906869  0.34528909 -0.75441229 -0.61037263 -0.57019944 -0.06581699\n",
      "  0.21792723  0.15864884 -0.6070325  -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.00392538 -0.03417451 -0.23880203 -0.06581699\n",
      "  1.08536305  0.15864884 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.4931532  -0.03417451  0.22515434 -0.06581699\n",
      " -0.6495086   0.15864884  0.85327631  0.20700552], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.4931532   0.31154437  1.28562604 -0.06581699\n",
      "  0.21792723 -2.05183018  0.85327631  1.25854437], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -2.68468588 -0.83531737 -0.57190973\n",
      "  0.21792723 -0.33256872 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609  0.31154437 -0.57019944 -1.07800247\n",
      " -0.6495086   0.89547517 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909  1.74071869 -0.61037263 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.82378628  0.29161908 -0.58164861], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573  3.73682347  0.31154437  0.68911071  0.44027575\n",
      " -0.6495086   1.14108395  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 1.18317632  1.31343391  0.4931532   0.54202361  0.68911071  0.44027575\n",
      "  1.95279888 -0.82378628  0.85327631  0.66705377], Predicted=red\n",
      "X=[-0.39906869  0.34528909  1.74071869 -0.84085188 -0.57019944 -0.06581699\n",
      "  1.08536305 -0.82378628 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.7426663  -0.61037263 -0.57019944 -1.07800247\n",
      " -0.6495086  -0.33256872 -0.83169539 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532  -0.84085188 -0.83531737 -0.57190973\n",
      " -0.6495086   1.14108395 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.00392538 -0.26465376 -0.57019944 -1.07800247\n",
      " -0.6495086   1.63230151 -0.83169539 -0.58164861], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.4931532  -0.84085188 -0.83531737 -0.57190973\n",
      " -0.6495086   0.40425762 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.2416925   2.04013874  2.94261308 -0.57190973\n",
      " -0.6495086   1.87791029  1.0779392   2.50724675], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573  0.4931532   1.11822174  0.22515434  0.44027575\n",
      "  0.21792723  0.15864884  0.29161908  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.61037263 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.5781775   0.51628197 -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.2436401   0.31154437 -0.23880203  0.44027575\n",
      " -0.6495086  -1.06939506  0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.7426663   0.88774249  2.47865671 -0.06581699\n",
      "  1.08536305 -0.33256872  1.0779392   3.03301617], Predicted=red\n",
      "X=[ 0.65576131  2.28157873 -0.50489919  0.54202361  0.22515434  1.45246124\n",
      " -0.6495086  -1.31500384  0.29161908  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.00587299  0.88774249  0.68911071 -0.57190973\n",
      " -0.6495086   0.15864884  0.85327631  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -1.00392538 -0.03417451 -0.23880203 -0.57190973\n",
      "  0.21792723  0.89547517 -0.27003816 -0.25304272], Predicted=blue\n",
      "X=[ 1.18317632  2.28157873 -0.75441229 -0.61037263 -0.83531737  1.45246124\n",
      "  3.68767053 -0.33256872 -1.16868973 -0.84453332], Predicted=blue\n",
      "X=[ 2.23800633 -0.62285573 -0.25538609  0.31154437  0.22515434  1.95855398\n",
      " -0.6495086   0.15864884  0.29161908  0.20700552], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.7426663  -0.03417451  0.22515434 -1.07800247\n",
      " -0.6495086  -0.5781775   0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.4931532  -0.61037263 -0.57019944 -0.57190973\n",
      " -0.6495086  -0.82378628 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.00392538 -0.84085188 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.5781775  -0.04537526 -0.84453332], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  1.2416925   0.54202361 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.82378628 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.25538609 -0.84085188 -0.83531737 -1.07800247\n",
      " -0.6495086  -1.31500384 -1.39335262 -1.17313921], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -1.18657076 -1.16671478 -1.07800247\n",
      " -0.6495086  -1.06939506 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401  -0.26465376 -0.23880203  3.4768322\n",
      "  0.21792723 -1.06939506 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.49120559  1.11822174  2.34609775 -1.07800247\n",
      " -0.6495086   0.64986639  1.75192788  2.31008322], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.74071869  1.46394061  1.28562604 -0.57190973\n",
      "  0.21792723 -1.06939506  1.41493354  1.25854437], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.00587299  0.54202361  0.22515434  0.44027575\n",
      " -0.6495086  -0.33256872 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -0.25538609 -1.18657076 -0.57019944 -0.06581699\n",
      "  0.21792723  0.64986639 -0.6070325  -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.7426663  -0.26465376 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.08695994 -1.39335262 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.00587299  0.88774249 -0.23880203  0.44027575\n",
      "  1.95279888 -0.5781775  -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.50489919 -0.84085188 -0.57019944 -0.57190973\n",
      "  0.21792723 -0.5781775  -0.83169539 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609  0.31154437  0.22515434 -0.57190973\n",
      " -0.6495086  -0.08695994 -0.83169539  0.20700552], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573 -1.00392538 -0.03417451 -1.16671478 -0.57190973\n",
      "  0.21792723 -1.8062214  -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.00587299 -0.26465376  0.22515434 -0.57190973\n",
      " -0.6495086   0.89547517  0.29161908  0.20700552], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -0.00587299 -0.84085188 -0.83531737 -0.06581699\n",
      "  0.21792723  1.38669273 -1.73034696 -1.17313921], Predicted=blue\n",
      "X=[ 0.65576131  2.28157873 -1.50295158 -0.26465376  0.68911071  0.44027575\n",
      "  0.21792723  0.64986639 -0.27003816  0.20700552], Predicted=blue\n",
      "X=[ 1.18317632  2.28157873 -1.50295158  0.31154437  0.22515434  1.95855398\n",
      "  1.08536305 -1.56061262  0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.4931532   0.88774249  0.22515434 -0.57190973\n",
      " -0.6495086  -0.5781775   0.51628197  0.20700552], Predicted=red\n",
      "X=[ 1.18317632  2.28157873 -0.50489919  0.31154437  0.22515434  2.97073946\n",
      " -0.6495086   0.40425762  0.85327631  0.20700552], Predicted=blue\n",
      "X=[ 1.18317632 -0.62285573  0.4931532  -0.84085188 -0.83531737  0.44027575\n",
      " -0.6495086  -1.8062214  -1.16868973 -0.84453332], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573  1.99023179  1.11822174  2.54493619  0.44027575\n",
      " -0.6495086   0.15864884  1.41493354  2.90157382], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.25538609 -0.61037263 -0.23880203 -0.57190973\n",
      " -0.6495086  -1.06939506 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -2.00197778  0.54202361  0.22515434  1.95855398\n",
      " -0.6495086   0.15864884  0.51628197  0.20700552], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573 -2.00197778 -1.18657076 -1.16671478  0.9463685\n",
      " -0.6495086   0.89547517 -1.95500986 -1.17313921], Predicted=blue\n",
      "X=[ 2.76542133  6.15415801  0.4931532   0.88774249  0.22515434  1.45246124\n",
      "  2.8202347   0.15864884 -0.27003816 -0.25304272], Predicted=blue\n",
      "X=[0.65576131 2.28157873 0.2436401  1.46394061 0.68911071 0.44027575\n",
      " 0.21792723 1.63230151 0.85327631 0.66705377], Predicted=blue\n",
      "X=[ 2.76542133 -0.62285573  1.2416925   1.11822174  1.28562604 -1.07800247\n",
      " -0.6495086   2.12351907  1.0779392   1.25854437], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -2.33896701 -1.4318327  -1.07800247\n",
      " -0.6495086  -0.08695994 -1.16868973 -1.43602393], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401   1.46394061  0.22515434 -0.57190973\n",
      " -0.6495086   1.87791029  0.85327631  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.00587299 -1.41705001 -1.4318327  -0.57190973\n",
      " -0.6495086   0.89547517 -1.39335262 -1.43602393], Predicted=red\n",
      "X=[-0.39906869  0.34528909  1.74071869 -0.26465376 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.5781775   0.85327631 -0.25304272], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573  0.2436401   0.88774249  0.68911071 -0.06581699\n",
      "  0.21792723 -0.5781775   0.29161908  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -0.61037263 -1.16671478  0.44027575\n",
      "  0.21792723  0.40425762 -1.16868973 -1.17313921], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  1.46394061  0.68911071 -0.57190973\n",
      "  0.21792723 -0.33256872  1.0779392   1.25854437], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.00587299  0.31154437 -0.23880203  0.44027575\n",
      " -0.6495086  -0.82378628  0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.75246468 -1.41705001 -1.4318327   0.9463685\n",
      " -0.6495086   0.89547517 -1.39335262 -1.43602393], Predicted=blue\n",
      "X=[ 0.12834631 -0.62285573  0.4931532   1.46394061  1.28562604 -0.57190973\n",
      " -0.6495086   0.89547517  0.85327631  1.25854437], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.25538609 -1.18657076 -0.57019944 -0.57190973\n",
      "  0.21792723  0.89547517 -0.83169539 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.00392538 -0.26465376 -0.57019944 -0.57190973\n",
      " -0.6495086  -0.08695994 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401   1.80965949  1.28562604 -1.07800247\n",
      " -0.6495086  -0.82378628  0.29161908  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.2416925   0.54202361 -0.23880203 -1.07800247\n",
      " -0.6495086   0.64986639 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401  -1.41705001 -1.16671478 -0.57190973\n",
      "  0.21792723  1.63230151 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  1.46394061  0.22515434  0.9463685\n",
      " -0.6495086  -0.5781775   0.29161908  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.26465376  0.22515434 -0.57190973\n",
      "  0.21792723 -1.06939506  0.29161908 -0.25304272], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -0.25538609  0.54202361  0.22515434 -0.57190973\n",
      " -0.6495086   1.38669273  0.85327631  0.20700552], Predicted=blue\n",
      "X=[ 1.71059132  0.34528909 -0.25538609 -0.03417451 -0.23880203 -0.06581699\n",
      "  1.08536305 -0.82378628 -0.04537526 -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.25538609  0.31154437  0.22515434  0.44027575\n",
      " -0.6495086   1.14108395 -0.04537526  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.61037263 -0.83531737 -0.57190973\n",
      "  0.21792723  0.89547517  0.29161908 -0.84453332], Predicted=red\n",
      "X=[ 1.71059132 -0.62285573 -1.00392538 -0.03417451 -0.57019944  1.45246124\n",
      " -0.6495086   0.64986639 -0.6070325  -0.58164861], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573 -2.25149087 -1.41705001 -1.4318327  -0.06581699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.6495086  -0.5781775  -0.83169539 -1.43602393], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -1.18657076 -0.83531737 -1.07800247\n",
      " -0.6495086   0.15864884 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.00587299  1.46394061  2.61121568  0.44027575\n",
      " -0.6495086  -1.31500384  1.41493354  2.31008322], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.75441229 -0.03417451 -0.57019944 -0.57190973\n",
      "  0.21792723 -0.5781775  -0.83169539 -0.58164861], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573 -1.00392538  0.88774249  0.22515434 -0.06581699\n",
      " -0.6495086   0.15864884  0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.25538609 -0.84085188 -0.83531737 -0.06581699\n",
      " -0.6495086   0.15864884 -1.39335262 -0.84453332], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.50489919  0.31154437  0.68911071 -0.06581699\n",
      "  0.21792723  0.64986639 -0.27003816  0.66705377], Predicted=red\n",
      "X=[ 0.65576131  0.34528909 -1.00392538  0.54202361  0.22515434  0.9463685\n",
      "  2.8202347  -1.31500384  0.29161908  0.20700552], Predicted=red\n",
      "X=[ 1.18317632  1.31343391 -0.50489919 -0.61037263 -0.83531737  0.44027575\n",
      "  1.08536305 -1.06939506 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573  1.2416925   0.88774249  1.28562604  0.9463685\n",
      " -0.6495086   1.14108395  0.51628197  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.9921794  -1.76276888 -0.83531737 -0.06581699\n",
      " -0.6495086  -1.8062214  -0.6070325  -0.84453332], Predicted=red\n",
      "X=[ 1.18317632  1.31343391  0.2436401   1.46394061  0.22515434 -0.06581699\n",
      "  1.08536305 -0.5781775   0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532  -1.41705001 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.33256872  0.29161908 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.50295158 -0.61037263 -0.83531737 -0.57190973\n",
      " -0.6495086  -0.08695994 -0.6070325  -0.84453332], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.7426663  -0.61037263 -0.57019944 -1.07800247\n",
      " -0.6495086  -0.82378628 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -1.50295158 -0.26465376  0.68911071 -0.57190973\n",
      " -0.6495086  -0.08695994 -0.27003816  0.20700552], Predicted=blue\n",
      "X=[-0.39906869  0.34528909 -0.00587299  1.46394061  2.94261308 -0.06581699\n",
      "  0.21792723  1.38669273  1.41493354  2.967295  ], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.75246468 -0.26465376 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.5781775  -0.27003816 -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.9921794   1.46394061  0.22515434 -1.07800247\n",
      " -0.6495086   0.40425762 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229 -0.03417451 -0.23880203 -1.07800247\n",
      " -0.6495086   0.15864884 -0.27003816 -0.25304272], Predicted=blue\n",
      "X=[ 2.76542133  2.28157873  0.2436401  -1.76276888 -1.16671478  1.95855398\n",
      "  4.55510636 -0.33256872 -1.95500986 -1.17313921], Predicted=blue\n",
      "X=[-0.39906869  0.34528909 -1.00392538  0.54202361  0.22515434 -0.57190973\n",
      "  0.21792723  2.36912785  0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.25538609 -0.26465376 -0.57019944 -1.07800247\n",
      " -0.6495086   0.40425762 -0.6070325  -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.00392538 -0.84085188 -0.57019944 -1.07800247\n",
      " -0.6495086  -1.31500384 -0.04537526 -0.58164861], Predicted=red\n",
      "X=[1.18317632 0.34528909 1.49120559 0.54202361 0.68911071 1.45246124\n",
      " 1.95279888 0.40425762 0.51628197 0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.2416925  -0.26465376 -0.23880203 -1.07800247\n",
      " -0.6495086   1.38669273 -0.83169539 -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -2.00197778  0.88774249  1.28562604 -0.06581699\n",
      " -0.6495086  -0.5781775   1.0779392   1.25854437], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573 -0.25538609 -1.18657076 -0.83531737  0.9463685\n",
      " -0.6495086   1.14108395 -1.16868973 -0.84453332], Predicted=blue\n",
      "X=[ 0.65576131 -0.62285573 -0.75441229  0.54202361 -0.57019944  0.44027575\n",
      " -0.6495086   0.40425762 -0.27003816 -0.58164861], Predicted=blue\n",
      "X=[-0.39906869  0.34528909 -1.00392538 -1.41705001 -1.16671478 -0.57190973\n",
      "  0.21792723 -0.82378628 -1.39335262 -1.17313921], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.4931532  -0.61037263 -0.23880203 -0.06581699\n",
      "  1.08536305  0.40425762  0.85327631  0.20700552], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.00587299  0.31154437 -0.57019944 -0.57190973\n",
      " -0.6495086  -1.06939506 -0.27003816 -0.58164861], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -1.00392538 -2.91516513 -1.4318327   0.44027575\n",
      " -0.6495086  -0.33256872 -2.2920042  -1.43602393], Predicted=red\n",
      "X=[ 0.12834631  1.31343391  0.4931532   1.11822174  0.22515434  0.44027575\n",
      "  1.95279888  0.40425762 -0.04537526  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.50295158 -0.03417451  0.22515434  0.44027575\n",
      " -0.6495086   0.15864884  1.41493354  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.49120559  0.54202361  0.68911071 -0.06581699\n",
      "  1.08536305  0.40425762  1.0779392   1.25854437], Predicted=red\n",
      "X=[ 1.18317632  2.28157873 -1.25343848  0.54202361  0.68911071  1.45246124\n",
      "  1.08536305  0.15864884  0.51628197  0.66705377], Predicted=blue\n",
      "X=[ 0.12834631 -0.62285573  0.2436401   1.46394061  0.22515434 -0.57190973\n",
      " -0.6495086   1.38669273 -0.6070325  -0.58164861], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573  0.2436401   0.54202361  0.22515434 -0.06581699\n",
      " -0.6495086  -0.82378628  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  0.34528909  0.9921794   0.31154437  0.22515434 -0.57190973\n",
      "  0.21792723  0.40425762 -0.27003816  0.66705377], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  2.23974489  0.31154437  0.22515434 -1.07800247\n",
      " -0.6495086   0.89547517  0.85327631  0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  1.2416925  -0.84085188 -0.83531737 -0.57190973\n",
      " -0.6495086  -0.82378628 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401   1.46394061  0.68911071 -0.06581699\n",
      " -0.6495086  -0.82378628  1.41493354  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -1.25343848 -0.61037263 -0.57019944  0.44027575\n",
      "  1.08536305 -0.5781775  -0.83169539 -0.58164861], Predicted=blue\n",
      "X=[-0.39906869  0.34528909  0.9921794   0.54202361  0.22515434 -0.57190973\n",
      "  0.21792723 -1.31500384  0.29161908  0.20700552], Predicted=red\n",
      "X=[ 0.65576131  1.31343391 -1.75246468 -0.03417451 -0.57019944  2.46464672\n",
      " -0.6495086  -0.82378628 -0.04537526 -0.58164861], Predicted=blue\n",
      "X=[ 1.71059132 -0.62285573  1.2416925   0.54202361  0.22515434  4.48901768\n",
      "  1.95279888  0.40425762  0.85327631  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.01948593 -2.68468588 -1.4318327   0.44027575\n",
      " -0.6495086  -1.56061262 -1.73034696 -1.43602393], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -0.84085188 -0.83531737  0.44027575\n",
      "  1.08536305  0.15864884 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[ 1.18317632  1.31343391  0.2436401   0.54202361  0.22515434  0.44027575\n",
      "  1.08536305 -0.33256872  0.51628197  0.20700552], Predicted=red\n",
      "X=[ 0.65576131  0.34528909  0.2436401  -0.84085188 -0.57019944 -1.07800247\n",
      " -0.6495086  -1.56061262 -0.04537526 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.25343848 -0.03417451 -0.57019944 -0.57190973\n",
      "  0.21792723 -1.56061262  0.29161908 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  1.46394061  1.28562604 -1.07800247\n",
      " -0.6495086   1.38669273  0.85327631  1.25854437], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.9921794  -0.03417451 -0.23880203 -0.57190973\n",
      " -0.6495086  -0.08695994  0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.50489919 -1.18657076 -1.4318327  -0.57190973\n",
      "  0.21792723 -0.82378628 -1.73034696 -1.43602393], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573  0.7426663   1.11822174  0.68911071 -1.07800247\n",
      " -0.6495086   0.15864884  1.0779392   0.66705377], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.00587299  1.46394061  2.61121568 -1.07800247\n",
      " -0.6495086   0.15864884  1.41493354  3.03301617], Predicted=blue\n",
      "X=[ 2.23800633  3.24972355  0.4931532   0.54202361  0.68911071  2.46464672\n",
      "  0.21792723 -0.08695994  1.0779392   0.66705377], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573 -0.75441229  1.80965949  0.68911071 -0.06581699\n",
      " -0.6495086  -0.33256872  0.51628197  0.66705377], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.50489919 -0.03417451  0.68911071 -0.06581699\n",
      " -0.6495086   0.40425762  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -0.50489919  0.31154437  0.22515434 -0.06581699\n",
      " -0.6495086   2.36912785  0.51628197  0.20700552], Predicted=blue\n",
      "X=[ 0.65576131  1.31343391  0.9921794  -1.41705001 -1.4318327  -0.06581699\n",
      " -0.6495086  -0.5781775  -2.62899854 -1.43602393], Predicted=red\n",
      "X=[ 0.65576131  2.28157873 -0.25538609  1.11822174  3.07517205 -0.06581699\n",
      "  0.21792723 -0.5781775   3.99855682  3.03301617], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.50295158  0.54202361  0.68911071 -0.06581699\n",
      " -0.6495086   0.64986639  0.85327631  0.66705377], Predicted=red\n",
      "X=[ 0.65576131  0.34528909 -0.50489919 -0.26465376 -0.23880203 -0.57190973\n",
      "  0.21792723  0.15864884 -0.6070325  -0.25304272], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573  0.7426663   0.31154437 -0.23880203  2.46464672\n",
      " -0.6495086   0.15864884  0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -1.25343848 -1.41705001 -1.16671478 -0.06581699\n",
      "  0.21792723 -1.56061262 -1.16868973 -1.17313921], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573 -0.50489919 -0.61037263 -0.83531737  0.44027575\n",
      " -0.6495086   1.38669273 -0.83169539 -0.84453332], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.7426663  -0.26465376 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.33256872 -0.04537526 -0.58164861], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -0.25538609  1.46394061 -0.23880203 -0.06581699\n",
      "  1.08536305 -2.29743896 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.7426663   0.54202361  0.22515434 -0.57190973\n",
      "  0.21792723  1.38669273  0.29161908  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401  -0.61037263 -0.57019944 -0.57190973\n",
      " -0.6495086   0.64986639 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[-0.39906869  0.34528909  1.2416925   1.46394061  0.68911071 -1.07800247\n",
      " -0.6495086   0.89547517  0.85327631  0.66705377], Predicted=blue\n",
      "X=[ 1.18317632  0.34528909  0.7426663  -0.26465376 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.08695994 -0.6070325  -0.71309097], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.00392538  0.88774249 -0.57019944 -1.07800247\n",
      " -0.6495086   0.64986639 -0.27003816 -0.58164861], Predicted=blue\n",
      "X=[ 0.12834631  1.31343391 -1.75246468 -1.18657076 -0.83531737 -0.57190973\n",
      " -0.6495086  -1.06939506 -0.6070325  -0.84453332], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.75441229  1.11822174  1.28562604  0.44027575\n",
      " -0.6495086  -1.06939506  1.41493354  1.25854437], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -0.50489919 -0.26465376 -0.23880203  0.44027575\n",
      "  1.08536305 -0.5781775   0.29161908  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -2.25149087 -1.41705001 -1.4318327  -0.06581699\n",
      " -0.6495086  -1.56061262 -0.83169539 -1.43602393], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.2436401   0.31154437 -0.23880203 -0.06581699\n",
      " -0.6495086   0.89547517 -0.6070325  -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.26465376  0.68911071 -1.07800247\n",
      " -0.6495086  -0.33256872  1.0779392   0.66705377], Predicted=red\n",
      "X=[ 0.65576131  0.34528909  0.7426663   0.54202361  0.68911071  0.9463685\n",
      "  0.21792723 -0.33256872  1.0779392   0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532   0.54202361  1.28562604 -0.06581699\n",
      "  0.21792723 -0.08695994  1.41493354  1.25854437], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  0.31154437 -0.23880203 -1.07800247\n",
      " -0.6495086   0.64986639  0.51628197  0.20700552], Predicted=red\n",
      "X=[ 1.18317632  0.34528909  0.2436401   0.54202361  0.68911071  1.45246124\n",
      "  1.08536305 -0.08695994  1.0779392   0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609  0.54202361  0.22515434 -1.07800247\n",
      " -0.6495086   0.15864884  0.29161908  0.66705377], Predicted=blue\n",
      "X=[1.71059132 2.28157873 1.49120559 1.11822174 1.28562604 1.45246124\n",
      " 1.08536305 0.40425762 1.0779392  1.25854437], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532   0.88774249  1.28562604 -1.07800247\n",
      " -0.6495086   0.89547517  1.0779392   1.25854437], Predicted=red\n",
      "X=[ 1.71059132  3.24972355  0.4931532   1.11822174  0.22515434 -0.06581699\n",
      " -0.6495086   1.14108395  0.51628197  0.20700552], Predicted=blue\n",
      "X=[ 1.18317632 -0.62285573 -0.50489919 -0.03417451  0.22515434  1.95855398\n",
      " -0.6495086  -0.5781775  -0.04537526 -0.25304272], Predicted=red\n",
      "X=[ 1.18317632  3.24972355  0.4931532   0.31154437 -0.23880203 -0.06581699\n",
      " -0.6495086   1.63230151 -0.04537526 -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.2436401  -0.03417451 -0.57019944 -1.07800247\n",
      " -0.6495086  -0.82378628 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[ 0.12834631  1.31343391  0.4931532   1.11822174  1.28562604 -0.06581699\n",
      " -0.6495086   1.63230151  0.85327631  0.66705377], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573  1.49120559  0.88774249  1.28562604  2.46464672\n",
      " -0.6495086   0.40425762  1.41493354  1.25854437], Predicted=red\n",
      "X=[ 2.23800633  1.31343391 -0.75441229 -0.61037263 -0.23880203  1.95855398\n",
      "  0.21792723 -0.82378628 -0.27003816 -0.25304272], Predicted=blue\n",
      "X=[ 2.76542133  5.18601319 -1.25343848  0.54202361  0.68911071  1.95855398\n",
      "  1.08536305  1.38669273  0.85327631  0.66705377], Predicted=blue\n",
      "X=[ 0.65576131  0.34528909  1.99023179  1.80965949  3.07517205 -0.06581699\n",
      " -0.6495086   1.38669273  1.75192788  2.967295  ], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.03417451  0.22515434 -1.07800247\n",
      " -0.6495086  -0.82378628  0.51628197  0.20700552], Predicted=blue\n",
      "X=[ 0.12834631  1.31343391  0.4931532  -0.03417451 -0.23880203 -0.06581699\n",
      "  0.21792723 -0.33256872  0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229  0.54202361  0.22515434 -1.07800247\n",
      " -0.6495086  -0.33256872  0.51628197  0.20700552], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573 -0.25538609  1.46394061  1.28562604 -1.07800247\n",
      " -0.6495086   3.10595419  1.41493354  1.25854437], Predicted=red\n",
      "X=[ 1.18317632  1.31343391  1.2416925   2.04013874  2.94261308 -0.06581699\n",
      "  1.08536305 -0.33256872  1.75192788  2.57296793], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.2436401  -1.41705001 -0.83531737  0.44027575\n",
      " -0.6495086  -0.33256872 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[ 2.23800633  0.34528909  0.4931532  -0.61037263 -0.23880203  1.45246124\n",
      "  0.21792723  0.15864884 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.25538609  1.11822174  3.07517205 -0.57190973\n",
      "  0.21792723  1.87791029  1.75192788  3.03301617], Predicted=red\n",
      "X=[ 0.65576131  2.28157873 -0.50489919 -0.84085188 -0.57019944  1.45246124\n",
      "  1.08536305  0.15864884 -0.04537526 -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -0.61037263 -0.23880203 -1.07800247\n",
      " -0.6495086  -0.5781775  -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.2416925  -1.18657076 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.82378628 -1.16868973 -1.17313921], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  1.49120559  0.54202361 -0.23880203 -0.57190973\n",
      "  0.21792723  0.15864884  0.29161908 -0.25304272], Predicted=red\n",
      "X=[ 2.23800633 -0.62285573 -0.00587299 -0.26465376 -0.23880203  0.9463685\n",
      "  1.08536305 -0.33256872 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.75246468  0.31154437 -0.57019944 -0.06581699\n",
      "  1.08536305 -1.56061262  0.29161908 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229  0.88774249  0.68911071  0.44027575\n",
      "  0.21792723 -0.82378628  1.41493354  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.00587299  1.11822174  0.68911071 -1.07800247\n",
      " -0.6495086   1.63230151  0.85327631  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.50489919  0.54202361  0.22515434 -0.57190973\n",
      "  0.21792723  1.14108395  0.51628197  0.20700552], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -0.03417451 -0.83531737 -0.06581699\n",
      "  0.21792723 -1.31500384 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[ 0.65576131  2.28157873  1.99023179  0.54202361  0.68911071 -0.06581699\n",
      " -0.6495086   1.38669273  0.51628197  0.66705377], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.9921794   0.54202361  0.22515434 -1.07800247\n",
      " -0.6495086   2.36912785 -0.04537526  0.20700552], Predicted=red\n",
      "X=[ 4.34766634  1.31343391  0.4931532   0.88774249  0.22515434  0.44027575\n",
      "  1.08536305  0.15864884 -0.04537526  0.20700552], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.00392538  0.88774249  0.68911071 -1.07800247\n",
      " -0.6495086   0.64986639  1.41493354  0.66705377], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -1.00392538  0.88774249  0.68911071 -0.57190973\n",
      " -0.6495086   1.38669273  0.85327631  0.66705377], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573 -0.75441229  0.54202361  0.22515434 -0.06581699\n",
      " -0.6495086   0.89547517  0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.7426663   1.11822174  1.28562604 -0.57190973\n",
      " -0.6495086   1.38669273  0.85327631  1.25854437], Predicted=red\n",
      "X=[ 2.23800633  1.31343391  1.2416925   1.46394061  0.68911071 -0.57190973\n",
      "  0.21792723 -0.82378628  0.85327631  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229 -0.03417451 -0.57019944 -0.06581699\n",
      " -0.6495086  -0.82378628 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -1.50295158 -0.61037263 -0.83531737  0.9463685\n",
      "  2.8202347  -1.56061262 -0.83169539 -0.84453332], Predicted=blue\n",
      "X=[ 0.65576131  2.28157873 -1.25343848 -0.61037263 -0.57019944 -0.57190973\n",
      "  0.21792723 -1.06939506  0.29161908 -0.58164861], Predicted=blue\n",
      "X=[ 1.18317632  3.24972355 -0.25538609  1.46394061 -0.23880203  2.97073946\n",
      " -0.6495086  -1.06939506 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.9921794   2.96205574  2.74377464 -0.57190973\n",
      " -0.6495086   0.15864884  0.51628197  2.90157382], Predicted=blue\n",
      "X=[ 0.12834631  1.31343391 -0.25538609  1.11822174  1.28562604 -0.06581699\n",
      "  0.21792723 -1.31500384  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573 -0.25538609 -0.03417451 -0.23880203  1.95855398\n",
      " -0.6495086   0.15864884 -0.6070325  -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -2.00197778  0.88774249  1.28562604 -0.06581699\n",
      "  1.08536305 -0.33256872  1.41493354  1.25854437], Predicted=red\n",
      "X=[ 0.12834631  0.34528909  1.74071869  0.88774249  0.68911071 -0.06581699\n",
      "  1.08536305  0.15864884  1.41493354  0.66705377], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  1.49120559 -1.18657076 -0.83531737 -0.06581699\n",
      " -0.6495086   0.64986639 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.25538609  1.11822174  0.68911071 -0.06581699\n",
      "  0.21792723  0.15864884  0.85327631  0.66705377], Predicted=red\n",
      "X=[ 0.65576131  0.34528909  0.2436401  -1.18657076 -0.83531737  1.45246124\n",
      "  0.21792723  1.14108395 -1.16868973 -0.84453332], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  1.99023179 -0.26465376  0.22515434  1.45246124\n",
      " -0.6495086   3.59717175  0.29161908  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.50295158  1.46394061  0.68911071 -1.07800247\n",
      " -0.6495086  -0.33256872  1.0779392   1.25854437], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.00392538 -0.03417451 -0.23880203 -1.07800247\n",
      " -0.6495086   0.89547517 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  0.31154437  0.68911071  0.44027575\n",
      " -0.6495086   0.15864884  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  0.34528909  1.49120559  0.88774249  1.28562604  0.44027575\n",
      " -0.6495086   0.40425762  1.0779392   1.25854437], Predicted=red\n",
      "X=[ 1.71059132  3.24972355 -1.50295158  0.31154437  0.22515434  1.45246124\n",
      "  1.08536305 -0.33256872  0.29161908  0.20700552], Predicted=blue\n",
      "X=[ 0.65576131 -0.62285573  0.7426663   1.11822174  1.28562604 -1.07800247\n",
      " -0.6495086   1.63230151  0.51628197  1.25854437], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401  -1.41705001 -0.83531737 -1.07800247\n",
      " -0.6495086   0.64986639 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -0.50489919  0.88774249  0.68911071  1.45246124\n",
      " -0.6495086  -0.5781775   0.85327631  0.66705377], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573  0.4931532   0.54202361  0.68911071 -0.06581699\n",
      " -0.6495086  -1.06939506  1.0779392   0.66705377], Predicted=red\n",
      "X=[ 2.23800633 -0.62285573  1.2416925  -0.26465376 -0.83531737  1.45246124\n",
      "  0.21792723  1.63230151 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.7426663   0.54202361  0.68911071 -0.57190973\n",
      "  0.21792723  0.15864884  0.51628197  0.66705377], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.75441229  1.46394061  0.68911071 -1.07800247\n",
      " -0.6495086   0.15864884  0.29161908  0.66705377], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.25538609 -1.41705001 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.33256872 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  1.74071869 -0.03417451  0.22515434 -1.07800247\n",
      " -0.6495086  -1.06939506 -0.04537526  0.20700552], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -0.25538609  0.54202361 -0.23880203 -0.06581699\n",
      " -0.6495086  -0.82378628 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -1.00392538 -1.18657076 -0.83531737  0.44027575\n",
      " -0.6495086  -0.33256872 -1.16868973 -0.84453332], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.00392538  0.88774249  0.22515434  0.44027575\n",
      " -0.6495086   1.14108395  0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -1.50295158 -1.18657076 -1.16671478 -0.57190973\n",
      " -0.6495086  -0.08695994 -0.83169539 -1.17313921], Predicted=blue\n",
      "X=[ 0.12834631 -0.62285573  0.2436401  -1.99324813 -1.4318327   1.95855398\n",
      "  1.08536305 -1.56061262 -1.95500986 -1.43602393], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.2416925   0.88774249  2.34609775  1.95855398\n",
      "  0.21792723  0.15864884  1.41493354  2.90157382], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.4931532  -0.61037263 -1.16671478 -0.06581699\n",
      " -0.6495086  -0.82378628 -0.04537526 -1.17313921], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.50489919 -0.03417451 -0.83531737 -0.57190973\n",
      " -0.6495086   0.64986639 -0.04537526 -0.84453332], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.2436401  -1.76276888 -1.16671478 -1.07800247\n",
      " -0.6495086   1.14108395 -0.27003816 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.7426663   0.88774249  2.47865671 -0.57190973\n",
      "  0.21792723 -0.33256872  1.41493354  2.31008322], Predicted=red\n",
      "X=[ 1.18317632  1.31343391 -1.00392538 -0.03417451 -0.23880203  1.45246124\n",
      " -0.6495086  -0.08695994 -0.6070325  -0.25304272], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573 -1.00392538 -0.03417451 -0.23880203 -0.57190973\n",
      " -0.6495086   1.38669273 -0.6070325   0.20700552], Predicted=blue\n",
      "X=[-0.39906869  0.34528909 -1.25343848  0.31154437  0.22515434  1.45246124\n",
      " -0.6495086  -0.82378628 -0.04537526  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.50295158 -0.26465376 -1.16671478 -1.07800247\n",
      " -0.6495086  -0.33256872 -1.39335262 -1.17313921], Predicted=blue\n",
      "X=[ 0.12834631 -0.62285573 -0.25538609  1.11822174  0.68911071 -0.06581699\n",
      "  1.08536305  1.38669273  0.85327631  0.66705377], Predicted=red\n",
      "X=[ 1.71059132  0.34528909 -0.50489919 -0.03417451 -0.23880203  2.46464672\n",
      "  3.68767053  1.63230151 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.25343848  0.01796149  2.47865671 -0.57190973\n",
      " -0.6495086   0.40425762  1.0779392   2.31008322], Predicted=red\n",
      "X=[ 2.23800633  5.18601319 -0.50489919  1.46394061  0.22515434 -0.06581699\n",
      "  0.21792723  0.15864884  1.41493354  0.20700552], Predicted=blue\n",
      "X=[ 0.12834631  0.34528909 -0.25538609  0.54202361 -0.23880203  0.9463685\n",
      "  0.21792723 -0.33256872  1.0779392  -0.25304272], Predicted=red\n",
      "X=[ 1.71059132  0.34528909 -0.25538609 -0.26465376 -0.57019944  1.45246124\n",
      " -0.6495086   0.89547517 -1.16868973 -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.4931532   2.04013874  2.61121568 -0.06581699\n",
      " -0.6495086   1.87791029  1.75192788  3.03301617], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573 -0.50489919 -0.26465376  0.22515434  1.45246124\n",
      " -0.6495086   2.36912785  0.51628197  0.20700552], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.25538609  0.31154437 -0.23880203 -1.07800247\n",
      " -0.6495086   1.63230151 -0.6070325  -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.00587299 -1.76276888 -0.83531737 -0.06581699\n",
      " -0.6495086  -0.33256872 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[ 0.12834631  0.34528909  0.2436401  -0.03417451  0.22515434  0.44027575\n",
      "  0.21792723 -0.33256872 -0.04537526  0.20700552], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.25538609 -1.18657076 -0.83531737  0.44027575\n",
      "  1.95279888 -0.33256872 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[ 1.18317632  2.28157873 -1.75246468 -0.26465376 -0.23880203  0.44027575\n",
      "  1.08536305  1.38669273  0.51628197 -0.25304272], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.25343848 -1.18657076 -1.16671478 -1.07800247\n",
      " -0.6495086  -1.31500384 -1.39335262 -1.17313921], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.00392538  0.88774249  1.28562604  2.97073946\n",
      " -0.6495086   0.40425762  1.41493354  1.25854437], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229 -1.41705001 -1.16671478 -1.07800247\n",
      " -0.6495086   0.40425762 -1.16868973 -1.17313921], Predicted=blue\n",
      "X=[-0.39906869  0.34528909  0.4931532  -0.61037263 -0.23880203 -0.57190973\n",
      "  0.21792723 -0.33256872  0.29161908 -0.25304272], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.7426663   0.54202361  0.22515434  0.44027575\n",
      " -0.6495086  -0.82378628  0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.00587299  1.11822174  0.68911071 -1.07800247\n",
      " -0.6495086   1.87791029  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  1.31343391  0.7426663   1.80965949  2.34609775 -1.07800247\n",
      " -0.6495086   0.40425762  1.75192788  2.24436204], Predicted=blue\n",
      "X=[-0.39906869  0.34528909  2.23974489  0.54202361  3.00889257 -1.07800247\n",
      " -0.6495086   2.86034541 -0.04537526  3.03301617], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.74071869  0.31154437  0.22515434 -0.57190973\n",
      " -0.6495086   1.87791029  0.51628197  0.66705377], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  0.7426663  -0.03417451 -0.23880203  0.44027575\n",
      " -0.6495086  -0.08695994 -0.04537526 -0.25304272], Predicted=red\n",
      "X=[ 0.12834631 -0.62285573 -1.00392538 -0.84085188 -0.83531737 -1.07800247\n",
      " -0.6495086  -0.33256872 -1.73034696 -1.17313921], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -2.00197778  0.54202361  0.68911071 -0.57190973\n",
      " -0.6495086   0.15864884  1.41493354  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -0.50489919 -1.18657076 -1.4318327  -0.57190973\n",
      "  0.21792723 -0.5781775  -2.62899854 -1.43602393], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229  1.80965949  0.68911071  1.45246124\n",
      "  0.21792723  0.15864884  0.85327631  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229 -0.61037263 -0.57019944 -1.07800247\n",
      " -0.6495086  -1.06939506 -0.04537526 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.25538609  0.54202361  0.68911071 -0.57190973\n",
      "  0.21792723 -0.5781775   0.29161908  0.20700552], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.25538609 -0.26465376 -0.57019944 -0.57190973\n",
      "  0.21792723 -1.8062214   0.29161908 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401   1.11822174  2.67749516 -1.07800247\n",
      " -0.6495086  -2.05183018  1.0779392   2.3758044 ], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.75441229  0.88774249  0.68911071 -1.07800247\n",
      " -0.6495086   0.15864884  0.85327631  0.20700552], Predicted=red\n",
      "X=[-0.39906869  0.34528909 -0.50489919 -0.03417451 -0.57019944  0.9463685\n",
      " -0.6495086  -0.82378628 -0.04537526 -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532   0.88774249  0.68911071 -1.07800247\n",
      " -0.6495086   1.87791029  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 2.76542133  0.34528909 -1.50295158 -0.26465376  0.68911071 -0.06581699\n",
      " -0.6495086   1.38669273  0.29161908  0.66705377], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573  0.7426663   1.80965949  2.47865671 -0.57190973\n",
      " -0.6495086   0.64986639  2.53824801  2.70441029], Predicted=red\n",
      "X=[ 2.76542133  2.28157873  0.2436401   0.88774249  0.68911071  1.45246124\n",
      "  0.21792723 -0.82378628  0.85327631  0.66705377], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919  1.46394061  0.68911071 -0.57190973\n",
      "  0.21792723  0.40425762  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 1.71059132  1.31343391 -1.75246468 -0.84085188 -0.83531737  0.9463685\n",
      "  0.21792723 -0.33256872 -1.16868973 -0.84453332], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573 -1.00392538  0.88774249  0.22515434 -0.57190973\n",
      " -0.6495086  -1.31500384  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 0.12834631  0.34528909 -0.50489919 -0.03417451 -0.83531737 -0.57190973\n",
      " -0.6495086   0.89547517 -1.39335262 -0.84453332], Predicted=blue\n",
      "X=[ 2.23800633 -0.62285573 -0.75441229 -1.41705001 -1.16671478  0.9463685\n",
      " -0.6495086  -0.08695994 -1.39335262 -1.17313921], Predicted=blue\n",
      "X=[ 1.18317632  0.34528909 -1.00392538 -0.03417451 -1.16671478  1.95855398\n",
      "  1.08536305  0.15864884 -1.73034696 -1.17313921], Predicted=blue\n",
      "X=[ 0.65576131 -0.62285573 -0.25538609 -1.18657076 -0.83531737  0.9463685\n",
      " -0.6495086  -0.08695994 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.00587299 -0.84085188 -1.16671478 -0.57190973\n",
      "  0.21792723 -0.08695994 -0.83169539 -0.84453332], Predicted=red\n",
      "X=[-0.39906869 -0.62285573  1.2416925  -0.03417451 -0.23880203 -1.07800247\n",
      " -0.6495086   1.38669273 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532  -0.03417451  0.22515434 -1.07800247\n",
      " -0.6495086  -1.8062214   0.51628197  0.20700552], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.4931532  -0.03417451  0.22515434 -1.07800247\n",
      " -0.6495086  -0.5781775  -0.04537526  0.20700552], Predicted=red\n",
      "X=[ 0.65576131  1.31343391  0.4931532  -0.26465376 -0.23880203  1.95855398\n",
      "  3.68767053  0.15864884 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[ 1.18317632  3.24972355 -0.50489919 -0.03417451 -0.23880203  0.44027575\n",
      "  0.21792723 -0.33256872 -0.6070325  -0.25304272], Predicted=blue\n",
      "X=[ 0.12834631  0.34528909 -0.50489919  0.88774249 -0.23880203 -0.06581699\n",
      "  1.08536305 -1.8062214  -0.04537526 -0.25304272], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.2436401   0.31154437  0.22515434 -1.07800247\n",
      " -0.6495086  -0.33256872  0.29161908  0.20700552], Predicted=red\n",
      "X=[ 1.18317632  3.24972355 -0.25538609  1.11822174  3.07517205  0.9463685\n",
      " -0.6495086   2.12351907  0.51628197  2.967295  ], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573 -1.75246468 -0.61037263 -0.83531737 -0.57190973\n",
      " -0.6495086  -1.31500384 -0.6070325  -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -1.25343848 -0.03417451 -0.23880203 -0.57190973\n",
      " -0.6495086  -0.82378628 -0.04537526  0.20700552], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573  0.2436401   1.46394061 -0.23880203 -1.07800247\n",
      " -0.6495086   0.89547517 -0.6070325  -0.58164861], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  0.9921794   1.11822174  0.22515434 -1.07800247\n",
      " -0.6495086   0.15864884  0.29161908 -0.25304272], Predicted=red\n",
      "X=[ 0.12834631  1.31343391 -0.25538609 -0.84085188 -0.57019944 -0.06581699\n",
      "  1.08536305  1.14108395 -0.27003816 -0.84453332], Predicted=blue\n",
      "X=[ 1.71059132 -0.62285573 -1.75246468 -0.26465376 -0.23880203  0.9463685\n",
      " -0.6495086  -0.08695994 -0.27003816 -0.25304272], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573 -0.25538609 -0.84085188 -1.16671478  2.97073946\n",
      " -0.6495086  -1.56061262 -0.27003816 -1.17313921], Predicted=red\n",
      "X=[ 0.65576131  2.28157873 -1.00392538 -2.68468588 -1.4318327  -0.06581699\n",
      "  0.21792723 -1.8062214  -1.39335262 -1.43602393], Predicted=red\n",
      "X=[ 1.71059132  3.24972355  0.4931532   0.88774249  0.68911071  1.95855398\n",
      " -0.6495086   0.15864884  0.51628197  0.66705377], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -1.00392538 -2.91516513 -1.4318327   0.44027575\n",
      "  0.21792723 -1.56061262 -0.83169539 -1.43602393], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.7426663  -0.84085188 -1.16671478 -1.07800247\n",
      " -0.6495086   1.87791029 -0.83169539 -1.43602393], Predicted=blue\n",
      "X=[ 0.12834631  1.31343391 -0.75441229 -0.26465376 -0.23880203 -0.06581699\n",
      "  0.21792723 -1.56061262 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -1.25343848 -0.03417451 -0.23880203 -0.06581699\n",
      " -0.6495086   0.40425762 -0.27003816 -0.25304272], Predicted=blue\n",
      "X=[-0.39906869 -0.62285573  0.9921794  -0.61037263 -0.83531737 -0.57190973\n",
      "  0.21792723 -1.06939506 -1.16868973 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573 -0.50489919 -0.03417451  0.22515434  0.44027575\n",
      " -0.6495086  -0.08695994 -0.27003816 -0.25304272], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.2436401   0.88774249 -0.57019944  0.9463685\n",
      "  2.8202347  -1.56061262  0.29161908 -0.58164861], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573 -0.50489919  0.54202361  0.22515434 -0.57190973\n",
      " -0.6495086  -0.33256872  0.29161908  0.20700552], Predicted=blue\n",
      "X=[-0.39906869  0.34528909 -0.75441229  0.54202361 -0.57019944 -1.07800247\n",
      " -0.6495086  -0.82378628  0.51628197 -0.58164861], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -0.75441229 -0.84085188 -0.83531737  0.44027575\n",
      "  1.95279888 -1.56061262 -1.95500986 -1.43602393], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573  2.23974489  0.54202361  3.00889257 -1.07800247\n",
      " -0.6495086   1.87791029  1.41493354  2.57296793], Predicted=red\n",
      "X=[ 0.12834631  0.34528909  0.7426663   0.88774249  0.68911071 -0.06581699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.21792723  0.64986639  0.51628197  0.66705377], Predicted=red\n",
      "X=[ 2.23800633  0.34528909 -0.00587299  1.46394061  1.28562604  0.44027575\n",
      "  0.21792723  0.89547517  0.85327631  1.25854437], Predicted=blue\n",
      "X=[ 0.12834631  0.34528909 -1.75246468  0.31154437 -0.57019944 -0.57190973\n",
      "  0.21792723 -0.82378628 -0.6070325  -0.58164861], Predicted=blue\n",
      "X=[-0.39906869  0.34528909  1.2416925  -1.18657076 -0.83531737  0.44027575\n",
      "  1.95279888  1.14108395 -0.27003816 -0.84453332], Predicted=red\n",
      "X=[ 1.71059132  0.34528909  1.49120559 -1.76276888 -1.16671478  1.45246124\n",
      "  0.21792723 -1.31500384 -1.39335262 -1.17313921], Predicted=red\n",
      "X=[-0.39906869  0.34528909  0.2436401  -1.18657076 -0.23880203 -0.57190973\n",
      "  0.21792723 -0.33256872  1.41493354 -0.25304272], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -0.50489919 -0.26465376  0.22515434 -0.57190973\n",
      " -0.6495086   0.89547517  1.0779392   0.20700552], Predicted=red\n",
      "X=[ 1.18317632 -0.62285573  1.2416925  -0.03417451  0.22515434  0.9463685\n",
      "  1.95279888  0.89547517 -1.16868973 -0.25304272], Predicted=red\n",
      "X=[ 0.65576131 -0.62285573 -0.75441229  2.38585761  0.68911071 -0.06581699\n",
      " -0.6495086   1.87791029  0.51628197  0.66705377], Predicted=red\n",
      "X=[-0.39906869 -0.62285573 -0.75441229 -0.26465376 -0.83531737 -0.06581699\n",
      " -0.6495086  -0.82378628 -0.27003816 -0.84453332], Predicted=red\n",
      "X=[-0.9264837  -0.62285573  1.49120559  1.80965949  3.07517205 -0.06581699\n",
      " -0.6495086   0.64986639  0.51628197  2.50724675], Predicted=red\n",
      "X=[ 1.71059132 -0.62285573 -1.25343848 -0.03417451 -0.57019944  0.9463685\n",
      " -0.6495086   0.15864884 -0.6070325  -0.58164861], Predicted=blue\n",
      "X=[-0.9264837  -0.62285573 -0.75441229 -0.26465376 -0.83531737 -0.06581699\n",
      " -0.6495086  -1.56061262 -0.27003816 -0.84453332], Predicted=red\n",
      "X=[ 1.18317632  1.31343391 -0.50489919 -0.84085188 -1.4318327   0.9463685\n",
      " -0.6495086  -0.82378628 -1.73034696 -1.43602393], Predicted=red\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_test_scaled)):\n",
    "    if np.round(ynew[i][0]) == 1:\n",
    "        pred_win = 'blue'\n",
    "    else:\n",
    "        pred_win = 'red'\n",
    "        \n",
    "    print(\"X=%s, Predicted=%s\" % (X_test_scaled[i], pred_win))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1223     red\n",
       "537      red\n",
       "1111    blue\n",
       "597     blue\n",
       "38       red\n",
       "        ... \n",
       "231      red\n",
       "1244     red\n",
       "657     blue\n",
       "1146     red\n",
       "535      red\n",
       "Name: winner, Length: 436, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19687466, 0.8031254 ],\n",
       "       [0.1676274 , 0.83237267],\n",
       "       [0.6729637 , 0.32703632],\n",
       "       [0.16435422, 0.8356458 ],\n",
       "       [0.5253265 , 0.4746735 ],\n",
       "       [0.516746  , 0.48325408],\n",
       "       [0.35923567, 0.6407643 ],\n",
       "       [0.3140553 , 0.68594474],\n",
       "       [0.15062346, 0.84937656],\n",
       "       [0.68458176, 0.31541824],\n",
       "       [0.49131754, 0.5086825 ],\n",
       "       [0.24023634, 0.75976366],\n",
       "       [0.4912488 , 0.5087512 ],\n",
       "       [0.20686412, 0.7931358 ],\n",
       "       [0.6021299 , 0.39787015],\n",
       "       [0.45415148, 0.54584855],\n",
       "       [0.3391969 , 0.66080314],\n",
       "       [0.52758175, 0.47241828],\n",
       "       [0.4986955 , 0.50130445],\n",
       "       [0.40127283, 0.59872717],\n",
       "       [0.610256  , 0.38974392],\n",
       "       [0.34333682, 0.6566631 ],\n",
       "       [0.23270138, 0.76729864],\n",
       "       [0.6962692 , 0.3037308 ],\n",
       "       [0.43885258, 0.5611474 ],\n",
       "       [0.31565106, 0.68434894],\n",
       "       [0.15118226, 0.8488177 ],\n",
       "       [0.5942041 , 0.40579587],\n",
       "       [0.57461804, 0.425382  ],\n",
       "       [0.54107994, 0.45892   ],\n",
       "       [0.2956809 , 0.70431906],\n",
       "       [0.37430292, 0.625697  ],\n",
       "       [0.44308215, 0.55691785],\n",
       "       [0.42550793, 0.57449204],\n",
       "       [0.40946603, 0.590534  ],\n",
       "       [0.45792967, 0.5420703 ],\n",
       "       [0.5316245 , 0.46837556],\n",
       "       [0.2021392 , 0.79786086],\n",
       "       [0.5850007 , 0.41499928],\n",
       "       [0.45340276, 0.5465973 ],\n",
       "       [0.18222594, 0.81777406],\n",
       "       [0.7779429 , 0.22205716],\n",
       "       [0.3311872 , 0.6688128 ],\n",
       "       [0.46547598, 0.53452396],\n",
       "       [0.36134195, 0.638658  ],\n",
       "       [0.44408932, 0.5559106 ],\n",
       "       [0.58441013, 0.41558984],\n",
       "       [0.44628793, 0.55371207],\n",
       "       [0.2490799 , 0.75092006],\n",
       "       [0.521446  , 0.47855404],\n",
       "       [0.42341405, 0.5765859 ],\n",
       "       [0.4735195 , 0.52648044],\n",
       "       [0.5225816 , 0.47741845],\n",
       "       [0.35654035, 0.6434597 ],\n",
       "       [0.6370841 , 0.36291593],\n",
       "       [0.14238991, 0.85761005],\n",
       "       [0.30292344, 0.6970765 ],\n",
       "       [0.21761316, 0.78238684],\n",
       "       [0.28901014, 0.71098983],\n",
       "       [0.59053254, 0.40946752],\n",
       "       [0.2988712 , 0.7011288 ],\n",
       "       [0.3025234 , 0.69747657],\n",
       "       [0.40800083, 0.5919991 ],\n",
       "       [0.16571741, 0.83428264],\n",
       "       [0.518288  , 0.48171195],\n",
       "       [0.4247262 , 0.57527375],\n",
       "       [0.41033664, 0.58966327],\n",
       "       [0.4665477 , 0.53345233],\n",
       "       [0.16947989, 0.8305201 ],\n",
       "       [0.06672207, 0.9332779 ],\n",
       "       [0.40739644, 0.59260356],\n",
       "       [0.34839666, 0.65160334],\n",
       "       [0.28979665, 0.7102033 ],\n",
       "       [0.45190147, 0.5480985 ],\n",
       "       [0.4650268 , 0.5349732 ],\n",
       "       [0.39695644, 0.60304356],\n",
       "       [0.53651434, 0.4634856 ],\n",
       "       [0.23731862, 0.7626814 ],\n",
       "       [0.26251382, 0.7374862 ],\n",
       "       [0.45476237, 0.54523766],\n",
       "       [0.35908118, 0.6409188 ],\n",
       "       [0.6208608 , 0.37913916],\n",
       "       [0.31378287, 0.68621707],\n",
       "       [0.61872846, 0.38127148],\n",
       "       [0.42504033, 0.57495964],\n",
       "       [0.83186364, 0.16813642],\n",
       "       [0.42788702, 0.572113  ],\n",
       "       [0.27776444, 0.72223556],\n",
       "       [0.35678262, 0.6432173 ],\n",
       "       [0.20290726, 0.7970928 ],\n",
       "       [0.42245296, 0.577547  ],\n",
       "       [0.36340445, 0.6365955 ],\n",
       "       [0.60765374, 0.3923462 ],\n",
       "       [0.62366915, 0.37633085],\n",
       "       [0.37204188, 0.62795806],\n",
       "       [0.19333483, 0.80666524],\n",
       "       [0.218873  , 0.78112704],\n",
       "       [0.43857497, 0.561425  ],\n",
       "       [0.49294034, 0.50705963],\n",
       "       [0.4247551 , 0.5752449 ],\n",
       "       [0.3917479 , 0.6082521 ],\n",
       "       [0.6623014 , 0.33769852],\n",
       "       [0.52779305, 0.47220698],\n",
       "       [0.7090141 , 0.2909858 ],\n",
       "       [0.35606742, 0.6439326 ],\n",
       "       [0.40408754, 0.59591246],\n",
       "       [0.58757025, 0.41242975],\n",
       "       [0.08457966, 0.91542035],\n",
       "       [0.8533278 , 0.14667219],\n",
       "       [0.5202083 , 0.4797916 ],\n",
       "       [0.3472142 , 0.65278584],\n",
       "       [0.44552356, 0.5544764 ],\n",
       "       [0.27280533, 0.72719467],\n",
       "       [0.24370895, 0.75629103],\n",
       "       [0.45733985, 0.5426602 ],\n",
       "       [0.20714793, 0.7928521 ],\n",
       "       [0.15756065, 0.84243935],\n",
       "       [0.4414039 , 0.5585961 ],\n",
       "       [0.19658886, 0.8034111 ],\n",
       "       [0.29294777, 0.7070522 ],\n",
       "       [0.3637702 , 0.6362298 ],\n",
       "       [0.48970097, 0.51029897],\n",
       "       [0.3278998 , 0.6721002 ],\n",
       "       [0.3307447 , 0.66925526],\n",
       "       [0.34691918, 0.6530808 ],\n",
       "       [0.5276632 , 0.47233683],\n",
       "       [0.36145395, 0.63854605],\n",
       "       [0.45138896, 0.54861104],\n",
       "       [0.38423598, 0.61576396],\n",
       "       [0.45037135, 0.5496287 ],\n",
       "       [0.65269566, 0.3473044 ],\n",
       "       [0.6782955 , 0.32170445],\n",
       "       [0.55348355, 0.44651645],\n",
       "       [0.39694965, 0.60305035],\n",
       "       [0.26323915, 0.73676085],\n",
       "       [0.49597454, 0.5040254 ],\n",
       "       [0.28207594, 0.717924  ],\n",
       "       [0.22325654, 0.77674353],\n",
       "       [0.3122857 , 0.68771434],\n",
       "       [0.36300892, 0.636991  ],\n",
       "       [0.42167595, 0.5783241 ],\n",
       "       [0.30281383, 0.6971862 ],\n",
       "       [0.3544461 , 0.6455538 ],\n",
       "       [0.5891869 , 0.4108131 ],\n",
       "       [0.2586286 , 0.74137133],\n",
       "       [0.2763533 , 0.7236467 ],\n",
       "       [0.37221438, 0.6277857 ],\n",
       "       [0.46580988, 0.53419006],\n",
       "       [0.37125543, 0.62874454],\n",
       "       [0.4266036 , 0.57339644],\n",
       "       [0.61190367, 0.3880963 ],\n",
       "       [0.6478267 , 0.3521734 ],\n",
       "       [0.40067852, 0.5993214 ],\n",
       "       [0.35378408, 0.6462159 ],\n",
       "       [0.66196716, 0.3380328 ],\n",
       "       [0.1430527 , 0.8569473 ],\n",
       "       [0.3518544 , 0.6481456 ],\n",
       "       [0.37534377, 0.62465626],\n",
       "       [0.42205077, 0.5779493 ],\n",
       "       [0.76039094, 0.23960908],\n",
       "       [0.76245445, 0.23754555],\n",
       "       [0.55460215, 0.44539788],\n",
       "       [0.74040526, 0.25959474],\n",
       "       [0.33619732, 0.6638026 ],\n",
       "       [0.3630697 , 0.6369303 ],\n",
       "       [0.41736466, 0.58263534],\n",
       "       [0.29726517, 0.7027348 ],\n",
       "       [0.3862854 , 0.61371464],\n",
       "       [0.38808206, 0.6119179 ],\n",
       "       [0.52781534, 0.47218466],\n",
       "       [0.41087312, 0.5891269 ],\n",
       "       [0.63467443, 0.36532557],\n",
       "       [0.46022913, 0.5397709 ],\n",
       "       [0.48017344, 0.5198266 ],\n",
       "       [0.49805558, 0.50194436],\n",
       "       [0.38239   , 0.61761   ],\n",
       "       [0.39071262, 0.6092874 ],\n",
       "       [0.26860267, 0.7313973 ],\n",
       "       [0.40738302, 0.59261703],\n",
       "       [0.36756077, 0.63243926],\n",
       "       [0.5799022 , 0.42009777],\n",
       "       [0.59791476, 0.40208524],\n",
       "       [0.4655856 , 0.53441447],\n",
       "       [0.2916382 , 0.7083618 ],\n",
       "       [0.69770455, 0.30229542],\n",
       "       [0.6421572 , 0.3578428 ],\n",
       "       [0.3954069 , 0.6045931 ],\n",
       "       [0.32174596, 0.678254  ],\n",
       "       [0.45869383, 0.5413062 ],\n",
       "       [0.41882488, 0.5811751 ],\n",
       "       [0.4274417 , 0.5725583 ],\n",
       "       [0.38517308, 0.61482686],\n",
       "       [0.39847314, 0.60152686],\n",
       "       [0.4665668 , 0.5334332 ],\n",
       "       [0.33231083, 0.66768914],\n",
       "       [0.19461542, 0.80538464],\n",
       "       [0.47864145, 0.5213585 ],\n",
       "       [0.29089734, 0.7091027 ],\n",
       "       [0.5420493 , 0.4579507 ],\n",
       "       [0.35064116, 0.64935887],\n",
       "       [0.64259607, 0.3574039 ],\n",
       "       [0.41165084, 0.58834916],\n",
       "       [0.54841226, 0.45158774],\n",
       "       [0.3847226 , 0.6152774 ],\n",
       "       [0.5014845 , 0.49851555],\n",
       "       [0.58730656, 0.41269344],\n",
       "       [0.46643767, 0.5335623 ],\n",
       "       [0.51235795, 0.48764205],\n",
       "       [0.43322113, 0.5667789 ],\n",
       "       [0.21405259, 0.7859474 ],\n",
       "       [0.3038313 , 0.6961687 ],\n",
       "       [0.37941366, 0.6205863 ],\n",
       "       [0.6333859 , 0.36661407],\n",
       "       [0.59862643, 0.4013736 ],\n",
       "       [0.4072504 , 0.5927496 ],\n",
       "       [0.32054585, 0.67945415],\n",
       "       [0.2844434 , 0.71555656],\n",
       "       [0.45996353, 0.54003644],\n",
       "       [0.4931827 , 0.5068172 ],\n",
       "       [0.42963722, 0.57036275],\n",
       "       [0.26702005, 0.73297995],\n",
       "       [0.54030186, 0.4596981 ],\n",
       "       [0.5278283 , 0.47217172],\n",
       "       [0.38560075, 0.6143992 ],\n",
       "       [0.52570194, 0.4742981 ],\n",
       "       [0.34166533, 0.6583347 ],\n",
       "       [0.19480729, 0.80519277],\n",
       "       [0.3922106 , 0.60778934],\n",
       "       [0.5362438 , 0.46375623],\n",
       "       [0.28452182, 0.7154782 ],\n",
       "       [0.65756345, 0.34243652],\n",
       "       [0.11317486, 0.8868252 ],\n",
       "       [0.1778152 , 0.82218486],\n",
       "       [0.3276539 , 0.67234606],\n",
       "       [0.47821823, 0.52178174],\n",
       "       [0.27922952, 0.7207704 ],\n",
       "       [0.42988253, 0.57011753],\n",
       "       [0.45977908, 0.5402209 ],\n",
       "       [0.40060106, 0.599399  ],\n",
       "       [0.31605878, 0.6839412 ],\n",
       "       [0.5037467 , 0.4962534 ],\n",
       "       [0.60797894, 0.39202103],\n",
       "       [0.55433625, 0.44566366],\n",
       "       [0.38214985, 0.6178502 ],\n",
       "       [0.43864614, 0.5613538 ],\n",
       "       [0.6302966 , 0.36970338],\n",
       "       [0.18377829, 0.8162217 ],\n",
       "       [0.39865556, 0.60134447],\n",
       "       [0.42176956, 0.5782304 ],\n",
       "       [0.654999  , 0.34500104],\n",
       "       [0.44563335, 0.55436665],\n",
       "       [0.3288044 , 0.6711956 ],\n",
       "       [0.56933457, 0.4306654 ],\n",
       "       [0.3435321 , 0.6564679 ],\n",
       "       [0.22417335, 0.7758267 ],\n",
       "       [0.40352234, 0.5964776 ],\n",
       "       [0.38194004, 0.61805993],\n",
       "       [0.52592564, 0.47407436],\n",
       "       [0.42790776, 0.57209224],\n",
       "       [0.5029938 , 0.49700612],\n",
       "       [0.5664926 , 0.43350744],\n",
       "       [0.36593154, 0.6340684 ],\n",
       "       [0.38024774, 0.6197522 ],\n",
       "       [0.4945609 , 0.5054391 ],\n",
       "       [0.5094982 , 0.49050182],\n",
       "       [0.48624405, 0.513756  ],\n",
       "       [0.29550543, 0.7044946 ],\n",
       "       [0.29542428, 0.70457566],\n",
       "       [0.49597648, 0.50402355],\n",
       "       [0.2786528 , 0.7213472 ],\n",
       "       [0.5721082 , 0.42789182],\n",
       "       [0.36019343, 0.63980657],\n",
       "       [0.43031687, 0.56968313],\n",
       "       [0.71631867, 0.28368127],\n",
       "       [0.39504075, 0.6049592 ],\n",
       "       [0.7072178 , 0.29278216],\n",
       "       [0.33549315, 0.6645069 ],\n",
       "       [0.48571515, 0.51428485],\n",
       "       [0.31946388, 0.6805361 ],\n",
       "       [0.5337882 , 0.46621183],\n",
       "       [0.8051974 , 0.19480269],\n",
       "       [0.4339395 , 0.5660605 ],\n",
       "       [0.50335443, 0.49664563],\n",
       "       [0.36263737, 0.63736266],\n",
       "       [0.5172129 , 0.48278707],\n",
       "       [0.2904495 , 0.70955056],\n",
       "       [0.49735075, 0.50264925],\n",
       "       [0.3152012 , 0.68479884],\n",
       "       [0.48836595, 0.511634  ],\n",
       "       [0.39713377, 0.6028662 ],\n",
       "       [0.5937005 , 0.4062995 ],\n",
       "       [0.4679025 , 0.53209746],\n",
       "       [0.16057359, 0.83942646],\n",
       "       [0.26144966, 0.7385503 ],\n",
       "       [0.48017448, 0.5198255 ],\n",
       "       [0.42379004, 0.57620996],\n",
       "       [0.34774712, 0.6522529 ],\n",
       "       [0.38528484, 0.6147151 ],\n",
       "       [0.57384783, 0.42615208],\n",
       "       [0.3222892 , 0.6777108 ],\n",
       "       [0.44188476, 0.5581153 ],\n",
       "       [0.42031735, 0.5796826 ],\n",
       "       [0.86015594, 0.13984405],\n",
       "       [0.43734205, 0.5626579 ],\n",
       "       [0.3950031 , 0.60499686],\n",
       "       [0.48005742, 0.5199426 ],\n",
       "       [0.45682353, 0.5431764 ],\n",
       "       [0.41389793, 0.586102  ],\n",
       "       [0.42331412, 0.5766859 ],\n",
       "       [0.5110561 , 0.48894387],\n",
       "       [0.65254545, 0.34745455],\n",
       "       [0.41900265, 0.5809974 ],\n",
       "       [0.5521985 , 0.4478014 ],\n",
       "       [0.28104123, 0.7189587 ],\n",
       "       [0.51985806, 0.48014185],\n",
       "       [0.34670419, 0.65329576],\n",
       "       [0.30713817, 0.69286186],\n",
       "       [0.19360138, 0.80639863],\n",
       "       [0.41751534, 0.58248466],\n",
       "       [0.56350696, 0.43649304],\n",
       "       [0.18656753, 0.8134325 ],\n",
       "       [0.55658245, 0.4434176 ],\n",
       "       [0.49967548, 0.5003246 ],\n",
       "       [0.467212  , 0.53278804],\n",
       "       [0.38196146, 0.6180385 ],\n",
       "       [0.7148517 , 0.28514823],\n",
       "       [0.4994718 , 0.50052816],\n",
       "       [0.33853906, 0.6614609 ],\n",
       "       [0.32770872, 0.6722913 ],\n",
       "       [0.28094015, 0.7190598 ],\n",
       "       [0.39902323, 0.60097677],\n",
       "       [0.38253143, 0.61746854],\n",
       "       [0.53910065, 0.46089938],\n",
       "       [0.34829554, 0.65170443],\n",
       "       [0.25922096, 0.74077904],\n",
       "       [0.31547546, 0.68452454],\n",
       "       [0.5093636 , 0.4906364 ],\n",
       "       [0.42944303, 0.570557  ],\n",
       "       [0.60735744, 0.39264256],\n",
       "       [0.15146999, 0.84853   ],\n",
       "       [0.28489518, 0.7151048 ],\n",
       "       [0.27281916, 0.7271808 ],\n",
       "       [0.511044  , 0.48895594],\n",
       "       [0.32942325, 0.67057675],\n",
       "       [0.41958582, 0.5804141 ],\n",
       "       [0.63048404, 0.36951602],\n",
       "       [0.5263938 , 0.47360626],\n",
       "       [0.42732057, 0.57267946],\n",
       "       [0.50995964, 0.49004033],\n",
       "       [0.2548204 , 0.7451796 ],\n",
       "       [0.22836535, 0.7716347 ],\n",
       "       [0.43943742, 0.56056255],\n",
       "       [0.8622946 , 0.13770537],\n",
       "       [0.37210625, 0.62789375],\n",
       "       [0.6440395 , 0.3559605 ],\n",
       "       [0.3171772 , 0.68282276],\n",
       "       [0.5243208 , 0.47567925],\n",
       "       [0.41845223, 0.58154774],\n",
       "       [0.3351934 , 0.6648066 ],\n",
       "       [0.3558385 , 0.6441615 ],\n",
       "       [0.36600313, 0.63399684],\n",
       "       [0.74615645, 0.2538435 ],\n",
       "       [0.33226085, 0.66773915],\n",
       "       [0.3636511 , 0.63634896],\n",
       "       [0.50786364, 0.49213642],\n",
       "       [0.37068507, 0.6293149 ],\n",
       "       [0.31493416, 0.68506587],\n",
       "       [0.41884956, 0.5811504 ],\n",
       "       [0.5454844 , 0.45451558],\n",
       "       [0.49544942, 0.5045506 ],\n",
       "       [0.35826963, 0.6417303 ],\n",
       "       [0.38958997, 0.61041   ],\n",
       "       [0.474708  , 0.525292  ],\n",
       "       [0.40182647, 0.5981735 ],\n",
       "       [0.33951128, 0.6604887 ],\n",
       "       [0.316168  , 0.68383193],\n",
       "       [0.43774003, 0.56226   ],\n",
       "       [0.42577782, 0.57422215],\n",
       "       [0.2917867 , 0.7082132 ],\n",
       "       [0.42644215, 0.5735578 ],\n",
       "       [0.46235904, 0.5376409 ],\n",
       "       [0.4006362 , 0.5993638 ],\n",
       "       [0.36973548, 0.6302645 ],\n",
       "       [0.874405  , 0.12559496],\n",
       "       [0.40076667, 0.5992333 ],\n",
       "       [0.44912395, 0.5508761 ],\n",
       "       [0.43587732, 0.5641227 ],\n",
       "       [0.6927514 , 0.30724856],\n",
       "       [0.48240936, 0.51759064],\n",
       "       [0.60348856, 0.3965114 ],\n",
       "       [0.57050085, 0.4294991 ],\n",
       "       [0.587124  , 0.41287598],\n",
       "       [0.4697348 , 0.5302652 ],\n",
       "       [0.32526323, 0.6747367 ],\n",
       "       [0.3120959 , 0.68790406],\n",
       "       [0.30671886, 0.6932811 ],\n",
       "       [0.4178508 , 0.5821492 ],\n",
       "       [0.28382275, 0.7161772 ],\n",
       "       [0.55811924, 0.44188073],\n",
       "       [0.31362674, 0.6863732 ],\n",
       "       [0.4776    , 0.5224    ],\n",
       "       [0.5827438 , 0.4172562 ],\n",
       "       [0.45789236, 0.5421076 ],\n",
       "       [0.510458  , 0.48954207],\n",
       "       [0.48968902, 0.51031095],\n",
       "       [0.36824977, 0.6317502 ],\n",
       "       [0.5190182 , 0.48098192],\n",
       "       [0.69356346, 0.30643654],\n",
       "       [0.29518133, 0.7048186 ],\n",
       "       [0.35475233, 0.64524764],\n",
       "       [0.5404226 , 0.45957732],\n",
       "       [0.28237072, 0.71762925],\n",
       "       [0.5186728 , 0.4813272 ],\n",
       "       [0.3671737 , 0.6328263 ],\n",
       "       [0.6150271 , 0.3849728 ],\n",
       "       [0.18076703, 0.819233  ],\n",
       "       [0.4914719 , 0.5085281 ],\n",
       "       [0.23287262, 0.7671274 ],\n",
       "       [0.5736602 , 0.4263398 ],\n",
       "       [0.4708807 , 0.52911925],\n",
       "       [0.30400717, 0.6959928 ],\n",
       "       [0.3559503 , 0.64404976],\n",
       "       [0.43445587, 0.56554407],\n",
       "       [0.6125068 , 0.38749316],\n",
       "       [0.6770881 , 0.3229119 ],\n",
       "       [0.2008614 , 0.7991386 ],\n",
       "       [0.12996854, 0.8700314 ],\n",
       "       [0.39881918, 0.6011808 ],\n",
       "       [0.49519765, 0.5048023 ],\n",
       "       [0.22036655, 0.7796335 ],\n",
       "       [0.49064746, 0.5093525 ],\n",
       "       [0.40490496, 0.59509504],\n",
       "       [0.384837  , 0.615163  ],\n",
       "       [0.67931527, 0.32068473],\n",
       "       [0.36046928, 0.63953066],\n",
       "       [0.39425   , 0.60574996]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew_new = np.round(ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1]\n",
       "Index: []"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yn = pd.DataFrame(ynew_new[:0])\n",
    "yn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report\n",
    "#print(classification_report(y_test, ynew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
